{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Tabular Models (XGBoost, LightGBM, CatBoost)\n",
    "\n",
    "**Purpose:** Train tabular models on processed datasets.\n",
    "\n",
    "**Models:**\n",
    "- XGBoost (gradient boosting)\n",
    "- LightGBM (fast gradient boosting)\n",
    "- CatBoost (categorical boosting)\n",
    "\n",
    "**Expected Runtime:** 20-40 minutes per model\n",
    "\n",
    "**Key Features:**\n",
    "- Auto-checkpointing every 30 minutes\n",
    "- W&B experiment tracking\n",
    "- Resume from last epoch on disconnect\n",
    "- GPU acceleration (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.colab_setup import setup_colab_environment, estimate_training_time_remaining\n",
    "from utils.checkpoint_manager import CheckpointManager\n",
    "\n",
    "# Auto-setup\n",
    "env_info = setup_colab_environment(\n",
    "    repo_url=\"https://github.com/yourusername/ml-factory.git\",\n",
    "    wandb_project=\"ohlcv-ml-factory\",\n",
    ")\n",
    "\n",
    "# Check remaining time\n",
    "remaining = estimate_training_time_remaining()\n",
    "print(f\"‚è±Ô∏è  Estimated time remaining: {remaining:.1f} hours\")\n",
    "\n",
    "if remaining < 2.0:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Less than 2 hours remaining - consider restarting runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Checkpoint Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SYMBOL = \"MES\"\n",
    "HORIZON = 20\n",
    "MODEL = \"xgboost\"  # or \"lightgbm\", \"catboost\"\n",
    "\n",
    "# Initialize checkpoint manager\n",
    "ckpt_mgr = CheckpointManager(\n",
    "    drive_path=\"/content/drive/MyDrive/ml_factory/checkpoints\",\n",
    "    wandb_project=\"ohlcv-ml-factory\",\n",
    "    auto_save_interval=1800,  # 30 minutes\n",
    ")\n",
    "\n",
    "# Initialize W&B run\n",
    "ckpt_mgr.init_wandb_run(\n",
    "    run_name=f\"{MODEL}_{SYMBOL}_h{HORIZON}\",\n",
    "    config={\"symbol\": SYMBOL, \"horizon\": HORIZON, \"model\": MODEL},\n",
    "    tags=[\"boosting\", SYMBOL, MODEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Datasets from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "DRIVE_DATA = Path(\"/content/drive/MyDrive/ml_factory/data/processed\") / SYMBOL\n",
    "LOCAL_DATA = Path(\"/content/data/splits/scaled\")\n",
    "LOCAL_DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy data from Drive to local (faster I/O during training)\n",
    "import shutil\n",
    "if not (LOCAL_DATA / \"X_train.npy\").exists():\n",
    "    print(\"Copying data from Drive to local disk...\")\n",
    "    shutil.copytree(DRIVE_DATA, LOCAL_DATA, dirs_exist_ok=True)\n",
    "    print(\"‚úÖ Data copied to local disk\")\n",
    "\n",
    "# Load data\n",
    "X_train = np.load(LOCAL_DATA / \"X_train.npy\")\n",
    "y_train = np.load(LOCAL_DATA / \"y_train.npy\")\n",
    "X_val = np.load(LOCAL_DATA / \"X_val.npy\")\n",
    "y_val = np.load(LOCAL_DATA / \"y_val.npy\")\n",
    "X_test = np.load(LOCAL_DATA / \"X_test.npy\")\n",
    "y_test = np.load(LOCAL_DATA / \"y_test.npy\")\n",
    "\n",
    "print(f\"\\nDataset shapes:\")\n",
    "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Val: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Existing Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to resume from checkpoint\n",
    "phase_name = f\"train_{MODEL}\"\n",
    "checkpoint = ckpt_mgr.load_latest_checkpoint(phase=phase_name)\n",
    "\n",
    "if checkpoint:\n",
    "    print(f\"\\n‚úÖ Resuming from checkpoint: {checkpoint['timestamp']}\")\n",
    "    model_state = checkpoint['state'].get('model_state')\n",
    "    last_epoch = checkpoint['state'].get('epoch', 0)\n",
    "    print(f\"Last completed epoch: {last_epoch}\")\n",
    "else:\n",
    "    print(\"\\nüÜï No checkpoint found - starting from scratch\")\n",
    "    model_state = None\n",
    "    last_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model with Auto-Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ModelRegistry\n",
    "\n",
    "# Initialize model\n",
    "model_class = ModelRegistry.get(MODEL)\n",
    "model = model_class()\n",
    "\n",
    "# Resume from checkpoint if available\n",
    "if model_state:\n",
    "    model.load_state(model_state)  # Implement load_state in BaseModel\n",
    "    print(f\"Model state restored from epoch {last_epoch}\")\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 8,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"use_gpu\": env_info['gpu_info']['available'],\n",
    "}\n",
    "\n",
    "# Custom callback for checkpointing\n",
    "class CheckpointCallback:\n",
    "    def __init__(self, ckpt_mgr, phase_name, interval=50):\n",
    "        self.ckpt_mgr = ckpt_mgr\n",
    "        self.phase_name = phase_name\n",
    "        self.interval = interval\n",
    "        \n",
    "    def __call__(self, epoch, metrics):\n",
    "        # Auto-save every N epochs or if time interval elapsed\n",
    "        if epoch % self.interval == 0 or self.ckpt_mgr.should_auto_save():\n",
    "            self.ckpt_mgr.save_checkpoint(\n",
    "                phase=self.phase_name,\n",
    "                state={\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state\": model.get_state(),  # Implement get_state in BaseModel\n",
    "                    \"metrics\": metrics,\n",
    "                },\n",
    "                metadata={\"symbol\": SYMBOL, \"horizon\": HORIZON, \"model\": MODEL},\n",
    "            )\n",
    "        \n",
    "        # Log to W&B\n",
    "        self.ckpt_mgr.log_metrics(metrics, step=epoch)\n",
    "\n",
    "# Train model\n",
    "callback = CheckpointCallback(ckpt_mgr, phase_name, interval=50)\n",
    "\n",
    "try:\n",
    "    training_metrics = model.fit(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val,\n",
    "        y_val=y_val,\n",
    "        config=config,\n",
    "        callbacks=[callback],  # Pass checkpoint callback\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Training completed successfully!\")\n",
    "    print(f\"Final metrics: {training_metrics}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed: {e}\")\n",
    "    # Save checkpoint on failure\n",
    "    ckpt_mgr.save_checkpoint(\n",
    "        phase=phase_name,\n",
    "        state={\"error\": str(e), \"epoch\": last_epoch},\n",
    "        metadata={\"symbol\": SYMBOL, \"status\": \"failed\"},\n",
    "        force=True,\n",
    "    )\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Generate predictions\n",
    "pred_output = model.predict(X_test)\n",
    "y_pred = pred_output.predictions\n",
    "y_proba = pred_output.probabilities\n",
    "\n",
    "# Calculate metrics\n",
    "test_metrics = {\n",
    "    \"test_accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"test_precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "    \"test_recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "    \"test_f1\": f1_score(y_test, y_pred, average='weighted'),\n",
    "}\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Log to W&B\n",
    "ckpt_mgr.log_metrics(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model to Drive and W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Define paths\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = f\"{MODEL}_{SYMBOL}_h{HORIZON}_{timestamp}\"\n",
    "\n",
    "DRIVE_MODELS = Path(\"/content/drive/MyDrive/ml_factory/models\")\n",
    "DRIVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = DRIVE_MODELS / f\"{model_name}.pkl\"\n",
    "\n",
    "# Save model to Drive\n",
    "model.save(model_path)\n",
    "print(f\"‚úÖ Model saved to: {model_path}\")\n",
    "\n",
    "# Upload to W&B\n",
    "if ckpt_mgr.wandb_run:\n",
    "    artifact = ckpt_mgr.wandb.Artifact(\n",
    "        name=model_name,\n",
    "        type=\"model\",\n",
    "        metadata={\"symbol\": SYMBOL, \"horizon\": HORIZON, \"model\": MODEL, **test_metrics},\n",
    "    )\n",
    "    artifact.add_file(str(model_path))\n",
    "    ckpt_mgr.wandb_run.log_artifact(artifact)\n",
    "    print(\"‚òÅÔ∏è  Model uploaded to W&B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish W&B Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_mgr.finish_wandb_run()\n",
    "print(\"\\n‚úÖ Training complete! Model saved and logged.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Train other tabular models (LightGBM, CatBoost)\n",
    "2. Proceed to sequence models (LSTM, GRU, TCN)\n",
    "3. Build heterogeneous ensemble with stacking meta-learner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
