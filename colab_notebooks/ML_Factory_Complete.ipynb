{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model Factory\n",
    "\n",
    "Train ML models on OHLCV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "!git clone https://github.com/Snehpatel101/Research.git /content/research 2>/dev/null || echo \"Done\"\n",
    "%cd /content/research\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/content/research')\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SYMBOL = \"SL\"\n",
    "DATA_FILE = \"/content/drive/MyDrive/si_historical_2019_2024.parquet\"\n",
    "HORIZON = 20\n",
    "MODELS = [\"xgboost\", \"lightgbm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(DATA_FILE)\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# Features\n",
    "df['return_1'] = df['close'].pct_change().shift(1)\n",
    "df['return_5'] = df['close'].pct_change(5).shift(1)\n",
    "df['return_20'] = df['close'].pct_change(20).shift(1)\n",
    "df['volatility'] = df['return_1'].rolling(20).std().shift(1)\n",
    "df['volume_ratio'] = (df['volume'] / df['volume'].rolling(20).mean()).shift(1)\n",
    "\n",
    "# Labels\n",
    "future_ret = df['close'].shift(-HORIZON) / df['close'] - 1\n",
    "threshold = future_ret.std() * 0.5\n",
    "df['label'] = 0\n",
    "df.loc[future_ret > threshold, 'label'] = 1\n",
    "df.loc[future_ret < -threshold, 'label'] = -1\n",
    "\n",
    "df = df.dropna().iloc[:-HORIZON]\n",
    "\n",
    "# Split\n",
    "features = ['return_1', 'return_5', 'return_20', 'volatility', 'volume_ratio']\n",
    "n = len(df)\n",
    "train = df.iloc[:int(n*0.7)]\n",
    "val = df.iloc[int(n*0.7):int(n*0.85)]\n",
    "test = df.iloc[int(n*0.85):]\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(train[features])\n",
    "X_val = scaler.transform(val[features])\n",
    "X_test = scaler.transform(test[features])\n",
    "y_train, y_val, y_test = train['label'].values, val['label'].values, test['label'].values\n",
    "\n",
    "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")\n",
    "print(f\"Labels: {pd.Series(y_train).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Models\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name in MODELS:\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "    if model_name == \"xgboost\":\n",
    "        from xgboost import XGBClassifier\n",
    "        model = XGBClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
    "    elif model_name == \"lightgbm\":\n",
    "        from lightgbm import LGBMClassifier\n",
    "        model = LGBMClassifier(n_estimators=100, max_depth=6, random_state=42, verbose=-1)\n",
    "    elif model_name == \"random_forest\":\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
    "    \n",
    "    # Shift labels to 0,1,2 for training\n",
    "    model.fit(X_train, y_train + 1)\n",
    "    \n",
    "    # Predict\n",
    "    val_pred = model.predict(X_val) - 1\n",
    "    test_pred = model.predict(X_test) - 1\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'val_acc': accuracy_score(y_val, val_pred),\n",
    "        'val_f1': f1_score(y_val, val_pred, average='macro'),\n",
    "        'test_acc': accuracy_score(y_test, test_pred),\n",
    "        'test_f1': f1_score(y_test, test_pred, average='macro'),\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"  Val Acc: {results[model_name]['val_acc']:.4f}, F1: {results[model_name]['val_f1']:.4f}\")\n",
    "    print(f\"  Test Acc: {results[model_name]['test_acc']:.4f}, F1: {results[model_name]['test_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Models\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "save_dir = Path(f\"/content/drive/MyDrive/ml_models/{SYMBOL}\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for name, data in results.items():\n",
    "    path = save_dir / f\"{name}_{SYMBOL}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "    joblib.dump(data['model'], path)\n",
    "    print(f\"Saved: {path}\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
