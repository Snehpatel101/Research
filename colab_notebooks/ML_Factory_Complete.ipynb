{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model Factory - Complete Pipeline\n",
    "\n",
    "**All-in-one notebook for training ML models on OHLCV data**\n",
    "\n",
    "## What This Notebook Does\n",
    "1. **Setup** - Mount Drive, install dependencies, configure environment\n",
    "2. **Data Pipeline** - Process raw OHLCV ‚Üí features ‚Üí labels ‚Üí splits\n",
    "3. **Train Models** - Train tabular models (XGBoost, LightGBM, CatBoost)\n",
    "4. **Evaluate** - Test set evaluation with trading metrics\n",
    "5. **Save** - Persist models to Google Drive\n",
    "\n",
    "## Expected Runtime\n",
    "- Data Pipeline: 30-60 minutes\n",
    "- Model Training: 20-40 minutes per model\n",
    "- Total: ~2 hours for full pipeline + 3 models\n",
    "\n",
    "## Requirements\n",
    "- Google Colab (free tier works, Pro recommended)\n",
    "- Raw OHLCV data in Google Drive\n",
    "- ~10GB free disk space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Environment Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository and install dependencies\n",
    "!git clone https://github.com/Snehpatel101/Research.git /content/research 2>/dev/null || echo \"Repo already cloned\"\n",
    "!cd /content/research && pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Colab environment\n",
    "import sys\n",
    "sys.path.insert(0, '/content/research')\n",
    "\n",
    "from notebooks.colab_setup import setup_colab_environment\n",
    "\n",
    "env_info = setup_colab_environment(\n",
    "    mount_drive=True,\n",
    "    use_gpu=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Environment Info:\")\n",
    "print(f\"  Running in Colab: {env_info.get('is_colab', False)}\")\n",
    "print(f\"  GPU available: {env_info.get('gpu_available', False)}\")\n",
    "print(f\"  Drive mounted: {env_info.get('drive_mounted', False)}\")\n",
    "\n",
    "# Check disk space\n",
    "import shutil\n",
    "total, used, free = shutil.disk_usage(\"/content\")\n",
    "print(f\"\\nüíæ Disk Space: {free // (1024**3)} GB free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - EDIT THESE VALUES\n",
    "from pathlib import Path\n",
    "\n",
    "SYMBOL = \"MES\"  # Symbol to train on (MES, MGC, etc.)\n",
    "HORIZON = 20    # Label horizon (5, 10, 15, 20)\n",
    "\n",
    "# Paths\n",
    "DRIVE_BASE = Path(\"/content/drive/MyDrive/ml_factory\")\n",
    "DRIVE_DATA = DRIVE_BASE / \"data\"\n",
    "DRIVE_MODELS = DRIVE_BASE / \"models\"\n",
    "DRIVE_CHECKPOINTS = DRIVE_BASE / \"checkpoints\"\n",
    "\n",
    "LOCAL_DATA = Path(\"/content/data\")\n",
    "LOCAL_OUTPUT = Path(\"/content/output\")\n",
    "\n",
    "# Create directories\n",
    "for d in [DRIVE_DATA / \"raw\", DRIVE_DATA / \"processed\", DRIVE_MODELS, DRIVE_CHECKPOINTS,\n",
    "          LOCAL_DATA / \"raw\", LOCAL_OUTPUT]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Configuration:\")\n",
    "print(f\"   Symbol: {SYMBOL}\")\n",
    "print(f\"   Horizon: {HORIZON}\")\n",
    "print(f\"   Drive base: {DRIVE_BASE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Data Pipeline (Phases 1-5)\n",
    "---\n",
    "\n",
    "**Phases:**\n",
    "1. Ingestion: Load raw 1-min OHLCV\n",
    "2. MTF Upscaling: Resample to 8 intraday timeframes\n",
    "3. Features: 180+ indicators (momentum, wavelets, microstructure)\n",
    "4. Labeling: Triple-barrier with Optuna optimization\n",
    "5. Adapters: Model-family data preparation (2D, 3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Copy raw data from Drive to local (faster I/O)\n",
    "raw_drive = DRIVE_DATA / \"raw\" / f\"{SYMBOL}_1m.parquet\"\n",
    "raw_local = LOCAL_DATA / \"raw\" / f\"{SYMBOL}_1m.parquet\"\n",
    "\n",
    "if not raw_local.exists():\n",
    "    print(f\"Copying data from Drive...\")\n",
    "    shutil.copy(raw_drive, raw_local)\n",
    "    print(f\"‚úÖ Copied to {raw_local}\")\n",
    "\n",
    "# Verify data\n",
    "df_raw = pd.read_parquet(raw_local)\n",
    "print(f\"\\nüìà Raw data: {df_raw.shape[0]:,} rows, {df_raw.shape[1]} columns\")\n",
    "print(f\"   Date range: {df_raw.index.min()} to {df_raw.index.max()}\")\n",
    "print(df_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for existing pipeline checkpoint\n",
    "import json\n",
    "\n",
    "checkpoint_file = LOCAL_OUTPUT / \"pipeline_state.json\"\n",
    "if checkpoint_file.exists():\n",
    "    with open(checkpoint_file) as f:\n",
    "        checkpoint = json.load(f)\n",
    "    print(f\"‚úÖ Found checkpoint from: {checkpoint.get('timestamp', 'unknown')}\")\n",
    "    print(f\"   Completed stages: {checkpoint.get('completed_stages', [])}\")\n",
    "else:\n",
    "    print(\"üÜï No checkpoint found - will run full pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data pipeline\n",
    "from src.pipeline.runner import PipelineRunner\n",
    "from src.pipeline.config import PipelineConfig\n",
    "\n",
    "config = PipelineConfig(\n",
    "    symbols=[SYMBOL],\n",
    "    data_dir=LOCAL_DATA,\n",
    "    output_dir=LOCAL_OUTPUT,\n",
    ")\n",
    "\n",
    "runner = PipelineRunner(config, resume=True)\n",
    "\n",
    "try:\n",
    "    print(\"\\nüöÄ Running data pipeline...\")\n",
    "    success = runner.run()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n‚úÖ Pipeline completed successfully!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Pipeline completed with some issues\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Pipeline failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy processed data to Drive (permanent storage)\n",
    "processed_local = LOCAL_DATA / \"splits\" / \"scaled\"\n",
    "processed_drive = DRIVE_DATA / \"processed\" / SYMBOL\n",
    "\n",
    "print(\"Copying processed data to Drive...\")\n",
    "shutil.copytree(processed_local, processed_drive, dirs_exist_ok=True)\n",
    "print(f\"‚úÖ Saved to {processed_drive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Load Processed Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed datasets\n",
    "from src.phase1.stages.datasets.container import TimeSeriesDataContainer\n",
    "\n",
    "data_dir = LOCAL_DATA / \"splits\" / \"scaled\"\n",
    "if not data_dir.exists():\n",
    "    # Load from Drive if local doesn't exist\n",
    "    data_dir = DRIVE_DATA / \"processed\" / SYMBOL\n",
    "    shutil.copytree(data_dir, LOCAL_DATA / \"splits\" / \"scaled\", dirs_exist_ok=True)\n",
    "    data_dir = LOCAL_DATA / \"splits\" / \"scaled\"\n",
    "\n",
    "container = TimeSeriesDataContainer.load(data_dir, horizon=HORIZON)\n",
    "print(f\"\\nüìä Loaded data container:\")\n",
    "print(f\"   {container}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Train Models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select models to train\n",
    "MODELS_TO_TRAIN = [\"xgboost\", \"lightgbm\"]  # Add \"catboost\" if installed\n",
    "\n",
    "print(f\"üéØ Will train: {MODELS_TO_TRAIN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ModelRegistry\n",
    "from src.models.trainer import Trainer\n",
    "from datetime import datetime\n",
    "\n",
    "trained_models = {}\n",
    "results = {}\n",
    "\n",
    "for model_name in MODELS_TO_TRAIN:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {model_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize trainer\n",
    "        trainer = Trainer(\n",
    "            model_name=model_name,\n",
    "            horizon=HORIZON,\n",
    "            output_dir=LOCAL_OUTPUT / \"runs\",\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        metrics = trainer.train(container)\n",
    "        \n",
    "        # Store results\n",
    "        trained_models[model_name] = trainer\n",
    "        results[model_name] = {\n",
    "            \"val_accuracy\": metrics.val_accuracy,\n",
    "            \"val_f1\": metrics.val_f1,\n",
    "            \"train_time\": metrics.training_time,\n",
    "        }\n",
    "        \n",
    "        # Save to Drive immediately\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model_path = DRIVE_MODELS / f\"{model_name}_{SYMBOL}_h{HORIZON}_{timestamp}.pkl\"\n",
    "        trainer.model.save(model_path)\n",
    "        print(f\"üíæ Saved to {model_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to train {model_name}: {e}\")\n",
    "        results[model_name] = {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    if \"error\" in metrics:\n",
    "        print(f\"\\n{model_name}: ‚ùå FAILED - {metrics['error']}\")\n",
    "    else:\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  Val Accuracy: {metrics['val_accuracy']:.4f}\")\n",
    "        print(f\"  Val F1: {metrics['val_f1']:.4f}\")\n",
    "        print(f\"  Train Time: {metrics['train_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Test Set Evaluation\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è **WARNING**: Test set evaluation is ONE-SHOT. Do not iterate on these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Get test data\n",
    "X_test, y_test = container.get_arrays(\"test\")\n",
    "\n",
    "print(\"‚ö†Ô∏è  TEST SET EVALUATION - ONE-SHOT GENERALIZATION ESTIMATE\")\n",
    "print(\"   Do NOT iterate on these results!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "for model_name, trainer in trained_models.items():\n",
    "    print(f\"\\n{model_name.upper()}:\")\n",
    "    \n",
    "    # Predict\n",
    "    pred_output = trainer.model.predict(X_test)\n",
    "    y_pred = pred_output.class_predictions\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    test_results[model_name] = {\"accuracy\": acc, \"f1\": f1}\n",
    "    \n",
    "    print(f\"  Test Accuracy: {acc:.4f}\")\n",
    "    print(f\"  Test F1 (macro): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report for best model\n",
    "if test_results:\n",
    "    best_model = max(test_results, key=lambda x: test_results[x]['f1'])\n",
    "    print(f\"\\nüìä Detailed Report for Best Model: {best_model.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    pred_output = trained_models[best_model].model.predict(X_test)\n",
    "    y_pred = pred_output.class_predictions\n",
    "    \n",
    "    print(classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=['Short (-1)', 'Neutral (0)', 'Long (1)']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 6: Save Final Results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Save summary to Drive\n",
    "summary = {\n",
    "    \"symbol\": SYMBOL,\n",
    "    \"horizon\": HORIZON,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"validation_results\": results,\n",
    "    \"test_results\": test_results,\n",
    "}\n",
    "\n",
    "summary_path = DRIVE_BASE / f\"run_summary_{SYMBOL}_h{HORIZON}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"‚úÖ Summary saved to {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ ALL DONE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìÅ Models saved to: {DRIVE_MODELS}\")\n",
    "print(f\"üìÅ Processed data: {DRIVE_DATA / 'processed' / SYMBOL}\")\n",
    "print(f\"üìÅ Run summary: {summary_path}\")\n",
    "print(\"\\nüöÄ Next steps:\")\n",
    "print(\"   1. Train neural models (LSTM, TCN, Transformer)\")\n",
    "print(\"   2. Build heterogeneous ensemble\")\n",
    "print(\"   3. Run walk-forward validation\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
