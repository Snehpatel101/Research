# -*- coding: utf-8 -*-
"""Prop Firm Challenge Simulator - VWAP LSTM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dYj0JVQ_FB0mTfgrKaQxoRNgu9G25Mtv
"""

!pip install pandas-ta
#!pip install onnxruntime-gpu  # Use this if you have a GPU runtime
!pip install onnxruntime    # Use this if you have a CPU runtime

#!/usr/bin/env python3
"""
Prop Firm Challenge Simulator - V6.3.6 Multi-Timeframe Model
UPDATED: Now supports SHORT signals with configurable flag

Key Features:
âœ… BUY-ONLY mode (original behavior)
âœ… SELL-ONLY mode (shorts only)
âœ… BOTH mode (longs and shorts)
âœ… All other features preserved from V6.3.6
"""
import pandas as pd
import numpy as np
import onnxruntime
import pickle
import os
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# =========================================================
# CONFIGURATION
# =========================================================

ONNX_MODEL_PATH = "/content/drive/MyDrive/AI_Models/MultiTF_Transformer_v6_3_7/multi_tf_transformer_v6_3_7.onnx"
SCALER_PATH = "/content/drive/MyDrive/AI_Models/MultiTF_Transformer_v6_3_7/multi_tf_transformer_v6_3_7_scaler.pkl"
CSV_PATH = "/content/drive/MyDrive/Futures Data/ES_continuous_3T.csv"

TEST_LAST_N_DAYS = 180
CONFIDENCE_THRESHOLDS_TO_TEST = [0.60, 0.65, 0.70, 0.75]

# ========== NEW: TRADING MODE CONFIGURATION ==========
TRADING_MODES_TO_TEST = ['BUY_ONLY', 'SELL_ONLY', 'BOTH']
# Options:
# - 'BUY_ONLY': Only take long positions (prediction == 1)
# - 'SELL_ONLY': Only take short positions (prediction == 2)
# - 'BOTH': Take both long and short positions

CHALLENGES = {
    '50K': {'name': '50K Challenge', 'capital': 50000, 'profit_target': 3000, 'max_loss': 2000, 'contracts': 1},
    '100K': {'name': '100K Challenge', 'capital': 100000, 'profit_target': 6000, 'max_loss': 3000, 'contracts': 1},
    '150K': {'name': '150K Challenge', 'capital': 150000, 'profit_target': 9000, 'max_loss': 4500, 'contracts': 1}
}

STOP_LOSS_POINTS = 8.0
PROFIT_TARGET_POINTS = 32.0
ES_MULTIPLIER = 50
COMMISSION_PER_CONTRACT = 2.50
SEQ_LEN = 80

FEATURE_COLS = [
    'fast_momentum', 'fast_trend_strength', 'fast_volatility_regime', 'fast_volume_regime', 'fast_price_position',
    'med_momentum', 'med_trend_strength', 'med_volatility_regime', 'med_volume_regime', 'med_price_position',
    'slow_momentum', 'slow_trend_strength', 'slow_volatility_regime', 'slow_volume_regime', 'slow_price_position',
    'tf_momentum_alignment', 'tf_trend_consistency', 'tf_volatility_divergence',
    'orderflow_proxy', 'liquidity_regime', 'hour_sin', 'hour_cos', 'regime_stability',
]

ENABLE_DETAILED_DIAGNOSTICS = False

# =========================================================
# FEATURE CALCULATION - MATCHING TRAINING EXACTLY
# =========================================================

def calculate_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    PRODUCTION-READY feature calculation using ROLLING WINDOWS.
    Matches training exactly - no resampling!

    Timeframe equivalents:
    - Fast:   Direct (3T bars)
    - Medium: 5-bar rolling (15min equivalent)
    - Slow:   20-bar rolling (60min equivalent)
    """
    df = df.copy()
    print(f"ðŸ“Š Calculating features for {len(df):,} bars (PRODUCTION-READY METHOD)...")

    # Import pandas_ta for consistent indicator calculation
    try:
        import pandas_ta as ta
    except ImportError:
        raise ImportError("pandas_ta required. Install with: pip install pandas_ta")

    # ========== ATR (used by all timeframes) ==========
    df['atr'] = ta.atr(df['high'], df['low'], df['close'], length=14)
    df['atr'] = df['atr'].fillna(method='ffill').fillna(1e-6)

    # ========== FAST TIMEFRAME (Direct 3T) ==========
    prefix = 'fast'

    # Momentum
    roc_short = df['close'].pct_change(3)
    roc_med = df['close'].pct_change(7)
    roc_long = df['close'].pct_change(14)
    df[f'{prefix}_momentum'] = (roc_short * 0.5 + roc_med * 0.3 + roc_long * 0.2).fillna(0)

    # Trend strength using ADX
    adx_df = ta.adx(df['high'], df['low'], df['close'], length=14)
    adx_val = adx_df['ADX_14'].fillna(0)
    plus_di = adx_df['DMP_14'].fillna(0)
    minus_di = adx_df['DMN_14'].fillna(0)

    trend_direction = np.sign(plus_di - minus_di)
    df[f'{prefix}_trend_strength'] = (adx_val / 100) * trend_direction

    # Volatility regime (rolling only)
    atr_ma = df['atr'].rolling(50, min_periods=20).mean()
    df[f'{prefix}_volatility_regime'] = df['atr'] / (atr_ma + 1e-6)

    # Volume regime (rolling only)
    vol_ma = df['volume'].rolling(20, min_periods=20).mean()
    df[f'{prefix}_volume_regime'] = df['volume'] / (vol_ma + 1e-6)

    # Price position (rolling only)
    rolling_min = df['close'].rolling(100, min_periods=50).min()
    rolling_max = df['close'].rolling(100, min_periods=50).max()
    df[f'{prefix}_price_position'] = (df['close'] - rolling_min) / (rolling_max - rolling_min + 1e-6)
    df[f'{prefix}_price_position'] = df[f'{prefix}_price_position'].fillna(0.5)

    # ========== MEDIUM TIMEFRAME (5-bar rolling = 15min) ==========
    prefix = 'med'
    window = 5

    # Create rolling aggregations
    rolling_high = df['high'].rolling(window).max()
    rolling_low = df['low'].rolling(window).min()
    rolling_close = df['close'].rolling(window).mean()

    # Momentum on rolled data
    roc_short = rolling_close.pct_change(3 * window)
    roc_med = rolling_close.pct_change(7 * window)
    roc_long = rolling_close.pct_change(14 * window)
    df[f'{prefix}_momentum'] = (roc_short * 0.5 + roc_med * 0.3 + roc_long * 0.2).fillna(0)

    # Trend strength (use longer ADX period)
    adx_df_med = ta.adx(df['high'], df['low'], df['close'], length=14 * window)
    adx_val_med = adx_df_med[f'ADX_{14*window}'].fillna(0)
    plus_di_med = adx_df_med[f'DMP_{14*window}'].fillna(0)
    minus_di_med = adx_df_med[f'DMN_{14*window}'].fillna(0)
    trend_direction_med = np.sign(plus_di_med - minus_di_med)
    df[f'{prefix}_trend_strength'] = (adx_val_med / 100) * trend_direction_med

    # Volatility regime
    atr_ma_med = df['atr'].rolling(50 * window, min_periods=20 * window).mean()
    df[f'{prefix}_volatility_regime'] = df['atr'] / (atr_ma_med + 1e-6)

    # Volume regime
    vol_ma_med = df['volume'].rolling(20 * window, min_periods=20 * window).mean()
    df[f'{prefix}_volume_regime'] = df['volume'] / (vol_ma_med + 1e-6)

    # Price position
    rolling_min_med = df['close'].rolling(100 * window, min_periods=50 * window).min()
    rolling_max_med = df['close'].rolling(100 * window, min_periods=50 * window).max()
    df[f'{prefix}_price_position'] = (df['close'] - rolling_min_med) / (rolling_max_med - rolling_min_med + 1e-6)
    df[f'{prefix}_price_position'] = df[f'{prefix}_price_position'].fillna(0.5)

    # ========== SLOW TIMEFRAME (20-bar rolling = 60min) ==========
    prefix = 'slow'
    window = 20

    # Create rolling aggregations
    rolling_high = df['high'].rolling(window).max()
    rolling_low = df['low'].rolling(window).min()
    rolling_close = df['close'].rolling(window).mean()

    # Momentum on rolled data
    roc_short = rolling_close.pct_change(3 * window)
    roc_med = rolling_close.pct_change(7 * window)
    roc_long = rolling_close.pct_change(14 * window)
    df[f'{prefix}_momentum'] = (roc_short * 0.5 + roc_med * 0.3 + roc_long * 0.2).fillna(0)

    # Trend strength (use longer ADX period)
    adx_df_slow = ta.adx(df['high'], df['low'], df['close'], length=14 * window)
    adx_val_slow = adx_df_slow[f'ADX_{14*window}'].fillna(0)
    plus_di_slow = adx_df_slow[f'DMP_{14*window}'].fillna(0)
    minus_di_slow = adx_df_slow[f'DMN_{14*window}'].fillna(0)
    trend_direction_slow = np.sign(plus_di_slow - minus_di_slow)
    df[f'{prefix}_trend_strength'] = (adx_val_slow / 100) * trend_direction_slow

    # Volatility regime
    atr_ma_slow = df['atr'].rolling(50 * window, min_periods=20 * window).mean()
    df[f'{prefix}_volatility_regime'] = df['atr'] / (atr_ma_slow + 1e-6)

    # Volume regime
    vol_ma_slow = df['volume'].rolling(20 * window, min_periods=20 * window).mean()
    df[f'{prefix}_volume_regime'] = df['volume'] / (vol_ma_slow + 1e-6)

    # Price position
    rolling_min_slow = df['close'].rolling(100 * window, min_periods=50 * window).min()
    rolling_max_slow = df['close'].rolling(100 * window, min_periods=50 * window).max()
    df[f'{prefix}_price_position'] = (df['close'] - rolling_min_slow) / (rolling_max_slow - rolling_min_slow + 1e-6)
    df[f'{prefix}_price_position'] = df[f'{prefix}_price_position'].fillna(0.5)

    # ========== CROSS-TIMEFRAME FEATURES ==========
    print(f"  ðŸ”„ Creating cross-timeframe features...")

    fast_mom_sign = np.sign(df['fast_momentum'])
    med_mom_sign = np.sign(df['med_momentum'])
    slow_mom_sign = np.sign(df['slow_momentum'])

    df['tf_momentum_alignment'] = np.where(
        (fast_mom_sign == med_mom_sign) & (med_mom_sign == slow_mom_sign),
        fast_mom_sign,
        0
    )

    df['tf_trend_consistency'] = (
        df['fast_trend_strength'] +
        df['med_trend_strength'] +
        df['slow_trend_strength']
    ) / 3

    vol_std = df[['fast_volatility_regime', 'med_volatility_regime', 'slow_volatility_regime']].std(axis=1)
    df['tf_volatility_divergence'] = vol_std

    # ========== MICROSTRUCTURE ==========
    df['orderflow_proxy'] = df['fast_momentum'] * df['fast_volume_regime']
    df['liquidity_regime'] = df['fast_volume_regime'] / (df['fast_volatility_regime'] + 0.1)

    # ========== REGIME STABILITY ==========
    alignment_series = df['tf_momentum_alignment']
    stability = np.zeros(len(alignment_series))

    if len(alignment_series) > 0:
        current_value = alignment_series.iloc[0]
        count = 1
        stability[0] = 1

        for i in range(1, len(alignment_series)):
            if alignment_series.iloc[i] == current_value:
                count += 1
            else:
                current_value = alignment_series.iloc[i]
                count = 1
            stability[i] = count

    df['regime_stability'] = np.minimum(stability / 20.0, 1.0)

    # ========== TEMPORAL ==========
    if isinstance(df.index, pd.DatetimeIndex):
        df['hour'] = df.index.hour
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    else:
        df['hour_sin'] = 0
        df['hour_cos'] = 1

    # ========== CLEANUP ==========
    df.drop(columns=['hour', 'atr'], inplace=True, errors='ignore')
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.fillna(method='ffill', inplace=True)
    df.fillna(0, inplace=True)

    nan_count = df[FEATURE_COLS].isna().sum().sum()
    inf_count = np.isinf(df[FEATURE_COLS].values).sum()

    print(f"âœ… Features calculated (PRODUCTION-READY METHOD):")
    print(f"   Fast: Direct 3T bars")
    print(f"   Medium: 5-bar rolling (15min equiv)")
    print(f"   Slow: 20-bar rolling (60min equiv)")
    print(f"   NaN values: {nan_count}")
    print(f"   Inf values: {inf_count}")

    return df

# =========================================================
# SIMULATOR
# =========================================================

class PropFirmSimulatorV636:
    def __init__(self, onnx_model_path, scaler_path, csv_path, test_last_n_days=None,
                 test_start_date=None, test_end_date=None):

        print(f"\n{'='*70}")
        print(f"ðŸš€ INITIALIZING MULTI-TF V6.3.6 SIMULATOR (PRODUCTION-READY)")
        print(f"{'='*70}")

        # Load ONNX model
        print(f"Loading Multi-TF V6.3.6 ONNX model...")
        providers = ['CUDAExecutionProvider'] if 'CUDAExecutionProvider' in onnxruntime.get_available_providers() else ['CPUExecutionProvider']
        self.session = onnxruntime.InferenceSession(onnx_model_path, providers=providers)
        print(f"âœ… Model loaded. Using: {self.session.get_providers()}")

        # Load scaler with diagnostics
        print("Loading scaler...")
        with open(scaler_path, 'rb') as f:
            scalers = pickle.load(f)

        print(f"\nðŸ” SCALER DIAGNOSTICS:")
        print(f"Scalers in file: {list(scalers.keys())}")

        for ticker, scaler in scalers.items():
            print(f"\n{ticker} scaler:")
            print(f"  center_ shape: {scaler.center_.shape}")
            print(f"  scale_ shape: {scaler.scale_.shape}")
            if len(scaler.center_) >= 5:
                print(f"  center_ sample (first 5): {scaler.center_[:5]}")
                print(f"  scale_ sample (first 5): {scaler.scale_[:5]}")

        # Use ES scaler (or first available)
        if 'ES' in scalers:
            self.scaler = scalers['ES']
            print(f"\nâœ… Using ES scaler")
        else:
            self.scaler = list(scalers.values())[0]
            print(f"\nâœ… Using {list(scalers.keys())[0]} scaler")

        # Verify scaler dimensions
        if self.scaler.center_.shape[0] != len(FEATURE_COLS):
            print(f"\nâš ï¸  WARNING: Scaler dimension mismatch!")
            print(f"   Scaler expects: {self.scaler.center_.shape[0]} features")
            print(f"   We're providing: {len(FEATURE_COLS)} features")
            print(f"   This will cause errors during inference!")

        # Load data
        print(f"\nLoading data from {csv_path}...")
        self.df = self._load_data(csv_path)
        print(f"âœ… Loaded {len(self.df):,} bars (full dataset)")

        # Filter to recent data
        self.df = self._filter_recent_data(test_last_n_days, test_start_date, test_end_date)

        # Split by month
        self.months = self._split_by_month()
        print(f"âœ… Found {len(self.months)} months in test window")
        print(f"{'='*70}\n")

        self.prediction_stats = {
            'total_bars': 0, 'predictions': [], 'confidences': [],
            'nan_errors': 0, 'inference_errors': 0
        }

    def _load_data(self, csv_path):
        df = pd.read_csv(csv_path)
        df.columns = [str(col).lower() for col in df.columns]

        time_col = None
        if 'timestamp' in df.columns:
            time_col = 'timestamp'
        elif 'time' in df.columns:
            time_col = 'time'
        elif 'ts_event' in df.columns:
            time_col = 'ts_event'
        else:
            raise ValueError("CSV must have 'time', 'timestamp', or 'ts_event' column")

        if df[time_col].dtype in ['int64', 'float64']:
            df['datetime'] = pd.to_datetime(df[time_col], unit='s')
        else:
            df['datetime'] = pd.to_datetime(df[time_col])

        df.set_index('datetime', inplace=True)
        df.sort_index(inplace=True)

        try:
            df.index = df.index.tz_localize('UTC').tz_convert('America/New_York')
        except TypeError:
            if df.index.tz is not None:
                df.index = df.index.tz_convert('America/New_York')

        if 'volume' not in df.columns:
            df['volume'] = 0

        return df[['open', 'high', 'low', 'close', 'volume']]

    def _filter_recent_data(self, test_last_n_days=None, test_start_date=None, test_end_date=None):
        print(f"\n{'='*70}")
        print("ðŸ“… FILTERING TO TEST WINDOW")
        print(f"{'='*70}")

        if test_start_date:
            start_dt = pd.to_datetime(test_start_date)
            end_dt = pd.to_datetime(test_end_date) if test_end_date else self.df.index[-1]
            history_start = start_dt - timedelta(days=90)

            print(f"Using specified date range:")
            print(f"  Test Period: {start_dt.date()} to {end_dt.date()}")
            print(f"  History Start: {history_start.date()} (for indicators)")

            filtered = self.df[history_start:end_dt].copy()
            self.test_start_date = start_dt

        elif test_last_n_days:
            most_recent_date = self.df.index[-1]
            test_start = most_recent_date - timedelta(days=test_last_n_days)
            history_start = test_start - timedelta(days=90)

            print(f"Using last {test_last_n_days} days:")
            print(f"  Most Recent: {most_recent_date.date()}")
            print(f"  Test Period: {test_start.date()} to {most_recent_date.date()}")
            print(f"  History Start: {history_start.date()} (for indicators)")

            filtered = self.df[history_start:].copy()
            self.test_start_date = test_start

        else:
            print("âš ï¸ Using ALL data (no filtering)")
            filtered = self.df.copy()
            self.test_start_date = self.df.index[0]

        print(f"\nFiltered dataset: {len(filtered):,} bars")
        print(f"Date range: {filtered.index[0].date()} to {filtered.index[-1].date()}")
        print(f"{'='*70}\n")

        return filtered

    def _split_by_month(self):
        test_data = self.df[self.df.index >= self.test_start_date]
        months = {}
        for year_month, group in test_data.groupby(test_data.index.to_period('M')):
            months[str(year_month)] = group
        return months

    def _softmax(self, x):
        e_x = np.exp(x - np.max(x))
        return e_x / e_x.sum(axis=0)

    def _predict_with_diagnostics(self, historical_data, bar_index=None, verbose=False):
        if len(historical_data) < SEQ_LEN:
            return 0, 0.0, None

        X_seq = historical_data[FEATURE_COLS].values

        if np.isnan(X_seq).any() or np.isinf(X_seq).any():
            self.prediction_stats['nan_errors'] += 1
            return 0, 0.0, None

        try:
            X_scaled = self.scaler.transform(X_seq)
        except Exception as e:
            if verbose:
                print(f"âŒ Scaler error at bar {bar_index}: {e}")
            self.prediction_stats['inference_errors'] += 1
            return 0, 0.0, None

        if np.isnan(X_scaled).any() or np.isinf(X_scaled).any():
            self.prediction_stats['nan_errors'] += 1
            return 0, 0.0, None

        X_onnx = X_scaled.astype(np.float32)[np.newaxis, :, :]

        try:
            outputs = self.session.run(None, {'input_sequence': X_onnx})

            # Get all outputs: logits, volatility, confidence
            logits_sequence = outputs[0]
            last_logits = logits_sequence[0, -1, :]

            # Get confidence from auxiliary head
            confidence_sequence = outputs[2]
            confidence_pred = float(confidence_sequence[0, -1])

            probs = self._softmax(last_logits)
            pred = int(np.argmax(probs))

            # Use auxiliary confidence (not max prob)
            conf = confidence_pred

            self.prediction_stats['total_bars'] += 1
            self.prediction_stats['predictions'].append(pred)
            self.prediction_stats['confidences'].append(conf)

            diagnostics = {
                'prediction': pred,
                'confidence': conf,
                'probs': probs,
                'feature_range': (X_seq.min(), X_seq.max()),
                'scaled_range': (X_scaled.min(), X_scaled.max()),
                'logits': last_logits,
                'confidence_pred': confidence_pred
            }

            return pred, conf, diagnostics

        except Exception as e:
            if verbose:
                print(f"âŒ ONNX prediction error at bar {bar_index}: {e}")
            self.prediction_stats['inference_errors'] += 1
            return 0, 0.0, None

    def run_challenge(self, month_data, challenge_config, month_name, entry_confidence, trading_mode='BUY_ONLY'):
        """
        Run challenge with configurable trading mode.

        Args:
            trading_mode: 'BUY_ONLY', 'SELL_ONLY', or 'BOTH'
        """
        capital = challenge_config['capital']
        profit_target = challenge_config['profit_target']
        max_loss = challenge_config['max_loss']
        contracts = challenge_config['contracts']

        pnl = 0.0
        trades = []
        in_position = False
        position_type = None
        entry_price = None
        stop_loss = None
        profit_target_price = None
        entry_time = None

        print(f"\n{'='*70}")
        print(f"ðŸ“… {month_name} | {challenge_config['name']}")
        print(f"{'='*70}")
        print(f"Capital: ${capital:,.0f} | Target: ${profit_target:,.0f} | Max Loss: ${max_loss:,.0f}")
        print(f"Contracts: {contracts} ES | Entry Conf: {entry_confidence:.1%}")
        print(f"Trading Mode: {trading_mode}")

        month_start_idx = self.df.index.get_loc(month_data.index[0])
        warmup_start = max(0, month_start_idx - 3000)
        full_data = self.df.iloc[warmup_start:month_start_idx + len(month_data)]

        print("Calculating features (PRODUCTION METHOD: rolling windows)...")
        full_data_with_features = calculate_features(full_data)

        month_start_in_full = len(full_data_with_features) - len(month_data)
        print(f"Processing {len(month_data):,} bars for trading...\n")

        # Trading loop
        for i in range(month_start_in_full + SEQ_LEN, len(full_data_with_features)):
            current_bar = full_data_with_features.iloc[i]
            timestamp = full_data_with_features.index[i]

            # Check exits
            if in_position:
                exit_price = None
                exit_reason = None

                if position_type == 'LONG':
                    if current_bar['low'] <= stop_loss:
                        exit_price = stop_loss
                        exit_reason = 'STOP_LOSS'
                    elif current_bar['high'] >= profit_target_price:
                        exit_price = profit_target_price
                        exit_reason = 'PROFIT_TARGET'

                elif position_type == 'SHORT':
                    # SHORT exits are inverted
                    if current_bar['high'] >= stop_loss:
                        exit_price = stop_loss
                        exit_reason = 'STOP_LOSS'
                    elif current_bar['low'] <= profit_target_price:
                        exit_price = profit_target_price
                        exit_reason = 'PROFIT_TARGET'

                if exit_price:
                    # Calculate P&L based on position type
                    if position_type == 'LONG':
                        points = exit_price - entry_price
                    else:  # SHORT
                        points = entry_price - exit_price

                    trade_pnl = (points * ES_MULTIPLIER * contracts) - (COMMISSION_PER_CONTRACT * contracts * 2)
                    pnl += trade_pnl

                    trades.append({
                        'entry_time': entry_time, 'exit_time': timestamp, 'type': position_type,
                        'entry': entry_price, 'exit': exit_price, 'reason': exit_reason,
                        'pnl': trade_pnl, 'total_pnl': pnl
                    })

                    print(f"ðŸ›‘ EXIT {position_type} @ {exit_price:.2f} | {exit_reason}")
                    print(f"   P&L: ${trade_pnl:+,.2f} | Total: ${pnl:+,.2f}")

                    in_position = False

                    if pnl >= profit_target:
                        print(f"\nðŸŽ‰ PROFIT TARGET REACHED: ${pnl:,.2f}")
                        return 'PASS', pnl, trades

                    if pnl <= -max_loss:
                        print(f"\nðŸ’¥ MAX LOSS HIT: ${pnl:,.2f}")
                        return 'FAIL', pnl, trades

            # Check for entry
            if not in_position:
                hist_window = full_data_with_features.iloc[i - SEQ_LEN: i]
                prediction, confidence, diagnostics = self._predict_with_diagnostics(hist_window, bar_index=i)

                if diagnostics is None:
                    continue

                # Determine if we should trade based on mode and prediction
                should_trade = False
                position_type = None

                if trading_mode == 'BUY_ONLY' and prediction == 1:
                    should_trade = True
                    position_type = 'LONG'
                elif trading_mode == 'SELL_ONLY' and prediction == 2:
                    should_trade = True
                    position_type = 'SHORT'
                elif trading_mode == 'BOTH':
                    if prediction == 1:
                        should_trade = True
                        position_type = 'LONG'
                    elif prediction == 2:
                        should_trade = True
                        position_type = 'SHORT'

                if should_trade and confidence >= entry_confidence:
                    in_position = True
                    entry_price = current_bar['close']
                    entry_time = timestamp

                    if position_type == 'LONG':
                        stop_loss = entry_price - STOP_LOSS_POINTS
                        profit_target_price = entry_price + PROFIT_TARGET_POINTS
                    else:  # SHORT
                        stop_loss = entry_price + STOP_LOSS_POINTS
                        profit_target_price = entry_price - PROFIT_TARGET_POINTS

                    print(f"\nðŸš€ ENTRY {position_type} @ {entry_price:.2f} | Conf: {confidence:.3f}")
                    print(f"   Stop: {stop_loss:.2f} | Target: {profit_target_price:.2f}")

        print(f"\nðŸ“Š Month ended | Final P&L: ${pnl:+,.2f}")

        if pnl >= profit_target:
            return 'PASS', pnl, trades
        elif pnl <= -max_loss:
            return 'FAIL', pnl, trades
        else:
            return 'INCOMPLETE', pnl, trades

    def run_all_months(self, challenge_type='100K', entry_confidence=0.75, trading_mode='BUY_ONLY'):
        challenge_config = CHALLENGES[challenge_type]

        print(f"\n{'='*70}")
        print(f"ðŸ† PROP FIRM CHALLENGE SIMULATOR - MULTI-TF V6.3.6")
        print(f"{'='*70}")
        print(f"Challenge: {challenge_config['name']}")
        print(f"Profit Target: ${challenge_config['profit_target']:,.0f}")
        print(f"Max Loss: ${challenge_config['max_loss']:,.0f}")
        print(f"Entry Confidence: {entry_confidence:.1%}")
        print(f"Trading Mode: {trading_mode}")
        print(f"{'='*70}")

        results = []

        for month_name in sorted(self.months.keys()):
            month_data = self.months[month_name]
            if len(month_data) < 100:
                continue

            result, pnl, trades = self.run_challenge(
                month_data, challenge_config, month_name, entry_confidence, trading_mode
            )

            results.append({'month': month_name, 'result': result, 'pnl': pnl, 'trades': len(trades)})

        self._print_summary(results, challenge_config, entry_confidence, trading_mode)
        return results

    def _print_summary(self, results, challenge_config, entry_confidence, trading_mode):
        print(f"\n{'='*70}")
        print(f"ðŸ“ˆ CHALLENGE SUMMARY: {challenge_config['name']} @ {entry_confidence:.1%} | {trading_mode}")
        print(f"{'='*70}")

        if not results:
            print("No months were tested. Check data and date ranges.")
            print(f"{'='*70}\n")
            return

        passed = sum(1 for r in results if r['result'] == 'PASS')
        failed = sum(1 for r in results if r['result'] == 'FAIL')
        incomplete = sum(1 for r in results if r['result'] == 'INCOMPLETE')
        total_months = len(results)

        print(f"\nTotal Months Tested: {total_months}")
        print(f"   âœ… PASSED:      {passed} ({passed/total_months*100:.1f}%)")
        print(f"   âŒ FAILED:      {failed} ({failed/total_months*100:.1f}%)")
        print(f"   â¸ï¸  INCOMPLETE:  {incomplete} ({incomplete/total_months*100:.1f}%)")

        print(f"\nðŸ“Š Monthly Results:")
        print(f"{'Month':<10} | {'Result':<10} | {'P&L':<12} | {'Trades'}")
        print(f"{'-'*10}-+-{'-'*10}-+-{'-'*12}-+-{'-'*6}")

        for r in results:
            icon = 'âœ…' if r['result'] == 'PASS' else 'âŒ' if r['result'] == 'FAIL' else 'â¸ï¸'
            print(f"{r['month']:<10} | {icon} {r['result']:<8} | ${r['pnl']:>10,.2f} | {r['trades']:>6}")

        if passed > 0:
            pass_rate = passed / total_months * 100
            print(f"\nðŸŽ¯ Challenge Pass Rate: {pass_rate:.1f}%")
            if pass_rate >= 50:
                print("âœ… Model shows STRONG promise for prop trading!")
            elif pass_rate >= 20:
                print("âœ… Model shows promise for prop trading!")
            else:
                print("âš ï¸  Moderate pass rate - consider optimization")

        print(f"\n{'='*70}")
        print(f"ðŸ“Š OVERALL STATISTICS")
        print(f"{'='*70}")
        print(f"Total bars processed: {self.prediction_stats['total_bars']:,}")
        print(f"NaN/Inf errors: {self.prediction_stats['nan_errors']:,}")
        print(f"Inference errors: {self.prediction_stats['inference_errors']:,}")

        if self.prediction_stats['confidences']:
            all_preds = np.array(self.prediction_stats['predictions'])
            all_confs = np.array(self.prediction_stats['confidences'])

            print(f"\nOverall prediction distribution:")
            print(f"  HOLD: {(all_preds == 0).sum():>6,} ({(all_preds == 0).mean()*100:>5.1f}%)")
            print(f"  BUY:  {(all_preds == 1).sum():>6,} ({(all_preds == 1).mean()*100:>5.1f}%)")
            print(f"  SELL: {(all_preds == 2).sum():>6,} ({(all_preds == 2).mean()*100:>5.1f}%)")

            print(f"\nOverall confidence statistics:")
            print(f"  Min:    {all_confs.min():.4f}")
            print(f"  Max:    {all_confs.max():.4f}")
            print(f"  Mean:   {all_confs.mean():.4f}")
            print(f"  Median: {np.median(all_confs):.4f}")
            print(f"  75th:   {np.percentile(all_confs, 75):.4f}")
            print(f"  90th:   {np.percentile(all_confs, 90):.4f}")

            # Show signal distribution based on trading mode
            if trading_mode == 'BUY_ONLY':
                print(f"\nSignal Distribution (BUY only):")
                for thresh in [0.55, 0.60, 0.65, 0.70, 0.75]:
                    buy_signals = ((all_preds == 1) & (all_confs >= thresh)).sum()
                    pct = buy_signals / len(all_confs) * 100
                    trades_per_day = (buy_signals / len(all_confs)) * 130
                    print(f"  >= {thresh:.2f}: {buy_signals:>6,} signals ({pct:>5.2f}%) | ~{trades_per_day:.1f} trades/day")

            elif trading_mode == 'SELL_ONLY':
                print(f"\nSignal Distribution (SELL only):")
                for thresh in [0.55, 0.60, 0.65, 0.70, 0.75]:
                    sell_signals = ((all_preds == 2) & (all_confs >= thresh)).sum()
                    pct = sell_signals / len(all_confs) * 100
                    trades_per_day = (sell_signals / len(all_confs)) * 130
                    print(f"  >= {thresh:.2f}: {sell_signals:>6,} signals ({pct:>5.2f}%) | ~{trades_per_day:.1f} trades/day")

            else:  # BOTH
                print(f"\nSignal Distribution (BUY + SELL):")
                for thresh in [0.55, 0.60, 0.65, 0.70, 0.75]:
                    buy_signals = ((all_preds == 1) & (all_confs >= thresh)).sum()
                    sell_signals = ((all_preds == 2) & (all_confs >= thresh)).sum()
                    total_signals = buy_signals + sell_signals
                    pct = total_signals / len(all_confs) * 100
                    trades_per_day = (total_signals / len(all_confs)) * 130
                    print(f"  >= {thresh:.2f}: {total_signals:>6,} signals ({pct:>5.2f}%) | "
                          f"BUY: {buy_signals:>4,} | SELL: {sell_signals:>4,} | ~{trades_per_day:.1f} trades/day")

        print(f"{'='*70}\n")

# =========================================================
# MAIN EXECUTION
# =========================================================

if __name__ == '__main__':

    print("\n" + "="*80)
    print("ðŸš€ PROP FIRM CHALLENGE SIMULATOR - V6.3.6 (WITH SHORT SUPPORT)")
    print("="*80)
    print(f"Model: Multi-Timeframe Transformer V6.3.6")
    print(f"Features: 23 indicators with ROLLING WINDOWS (production-ready)")
    print(f"  - Fast: Direct 3T bars")
    print(f"  - Medium: 5-bar rolling (15min equiv)")
    print(f"  - Slow: 20-bar rolling (60min equiv)")
    print(f"Sequence: 80 bars")
    print(f"Trading Modes: {', '.join(TRADING_MODES_TO_TEST)}")
    print(f"ONNX: {ONNX_MODEL_PATH}")
    print(f"Scaler: {SCALER_PATH}")
    print(f"Data: {CSV_PATH}")
    print(f"Test Window: Last {TEST_LAST_N_DAYS} days")
    print(f"Diagnostics: {'ENABLED' if ENABLE_DETAILED_DIAGNOSTICS else 'DISABLED'}")
    print("="*80 + "\n")

    # Check for pandas_ta
    try:
        import pandas_ta as ta
        print("âœ… pandas_ta found (required for indicator calculation)\n")
    except ImportError:
        print("âŒ pandas_ta NOT found!")
        print("   Install with: pip install pandas_ta")
        print("   This is REQUIRED for V6.3.6 feature calculation\n")
        exit(1)

    # Initialize simulator
    simulator = PropFirmSimulatorV636(
        ONNX_MODEL_PATH,
        SCALER_PATH,
        CSV_PATH,
        test_last_n_days=TEST_LAST_N_DAYS,
    )

    all_results = {}

    # Loop through trading modes, confidence thresholds, and challenges
    for mode in TRADING_MODES_TO_TEST:
        all_results[mode] = {}

        for conf in CONFIDENCE_THRESHOLDS_TO_TEST:
            all_results[mode][conf] = {}

            print(f"\n{'='*80}")
            print(f"ðŸš€ðŸš€ðŸš€ TESTING MODE: {mode} | CONFIDENCE: {conf:.1%} ðŸš€ðŸš€ðŸš€")
            print(f"{'='*80}")

            for challenge_key in CHALLENGES.keys():
                print(f"\nðŸš€ Starting {CHALLENGES[challenge_key]['name']} @ {conf:.1%} ({mode})...")

                # Reset stats
                simulator.prediction_stats = {
                    'total_bars': 0, 'predictions': [], 'confidences': [],
                    'nan_errors': 0, 'inference_errors': 0
                }

                results = simulator.run_all_months(
                    challenge_type=challenge_key,
                    entry_confidence=conf,
                    trading_mode=mode
                )

                all_results[mode][conf][challenge_key] = results

    # =========================================================
    # FINAL SUMMARY
    # =========================================================

    print("\n" + "="*80)
    print("ðŸŽ¯ FINAL SUMMARY - ALL TESTS")
    print("="*80)

    for mode in TRADING_MODES_TO_TEST:
        print(f"\n{'='*80}")
        print(f"ðŸ“Š TRADING MODE: {mode}")
        print(f"{'='*80}")

        for conf in CONFIDENCE_THRESHOLDS_TO_TEST:
            print(f"\nðŸŽ¯ Confidence Threshold: {conf:.1%}")
            print("-" * 80)

            for challenge_key in CHALLENGES.keys():
                results = all_results[mode][conf][challenge_key]
                if not results:
                    continue

                passed = sum(1 for r in results if r['result'] == 'PASS')
                failed = sum(1 for r in results if r['result'] == 'FAIL')
                incomplete = sum(1 for r in results if r['result'] == 'INCOMPLETE')
                total = len(results)

                total_trades = sum(r['trades'] for r in results)
                pass_rate = (passed / total * 100) if total > 0 else 0

                print(f"{CHALLENGES[challenge_key]['name']:15s}: Pass={passed:2d}/{total:2d} ({pass_rate:5.1f}%) | "
                      f"Fail={failed:2d} | Inc={incomplete:2d} | Trades={total_trades:3d}")

    print("\n" + "="*80)
    print("âœ… ALL SIMULATIONS COMPLETE!")
    print("="*80)

    # Performance comparison
    print("\n" + "="*80)
    print("ðŸ“Š PERFORMANCE COMPARISON: BUY vs SELL vs BOTH")
    print("="*80)

    for conf in CONFIDENCE_THRESHOLDS_TO_TEST:
        print(f"\nðŸŽ¯ @ {conf:.1%} confidence:")
        print("-" * 80)

        for challenge_key in CHALLENGES.keys():
            print(f"\n{CHALLENGES[challenge_key]['name']}:")

            for mode in TRADING_MODES_TO_TEST:
                results = all_results[mode][conf][challenge_key]
                if not results:
                    continue

                passed = sum(1 for r in results if r['result'] == 'PASS')
                total = len(results)
                total_trades = sum(r['trades'] for r in results)
                pass_rate = (passed / total * 100) if total > 0 else 0

                print(f"  {mode:12s}: {pass_rate:5.1f}% pass rate | {total_trades:3d} trades")

    # Diagnostics
    if simulator.prediction_stats['confidences']:
        all_confs = np.array(simulator.prediction_stats['confidences'])
        all_preds = np.array(simulator.prediction_stats['predictions'])

        print("\n" + "="*80)
        print("ðŸ’¡ DIAGNOSTIC SUMMARY")
        print("="*80)
        print(f"\nðŸ“Š Overall Prediction Distribution:")
        print(f"  HOLD: {(all_preds == 0).sum():>6,} ({(all_preds == 0).mean()*100:>5.1f}%)")
        print(f"  BUY:  {(all_preds == 1).sum():>6,} ({(all_preds == 1).mean()*100:>5.1f}%)")
        print(f"  SELL: {(all_preds == 2).sum():>6,} ({(all_preds == 2).mean()*100:>5.1f}%)")

        print(f"\nðŸ“Š Model Confidence Analysis:")
        print(f"  Maximum confidence: {all_confs.max():.4f}")
        print(f"  90th percentile:    {np.percentile(all_confs, 90):.4f}")
        print(f"  Average confidence: {all_confs.mean():.4f}")

        if all_confs.max() < 0.70:
            print(f"\nðŸš¨ CRITICAL: Maximum confidence below 0.70!")
        else:
            print(f"\nâœ… Model confidence levels HEALTHY")

    print("\n" + "="*80)
    print("ðŸ“ KEY INSIGHTS")
    print("="*80)
    print("1. Compare BUY_ONLY vs SELL_ONLY pass rates")
    print("2. Check if BOTH mode improves or hurts performance")
    print("3. Look at trade counts - more trades â‰  better performance")
    print("4. Identify which mode is most consistent across months")
    print("5. Consider if SHORT signals need different parameters")
    print("="*80 + "\n")

"""# New Section"""