{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model Factory - Complete Pipeline & Training\n",
    "\n",
    "This notebook runs the **complete ML pipeline** from raw data to trained models.\n",
    "\n",
    "## What This Notebook Does\n",
    "1. **Setup** - Mount Drive, install dependencies, detect GPU\n",
    "2. **Phase 1** - Data pipeline (clean → features → labels → splits)\n",
    "3. **Phase 2** - Model training (single or multiple models)\n",
    "4. **Phase 3** - Cross-validation (optional)\n",
    "5. **Phase 4** - Ensemble training (optional)\n",
    "\n",
    "## Quick Start\n",
    "1. Upload your data to `My Drive/research/data/raw/`\n",
    "2. Run cells in order (or use Runtime → Run all)\n",
    "3. Choose your training options in Section 4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1.1 Mount Google Drive & Clone Repository { display-mode: \"form\" }\n",
    "#@markdown Run this cell to mount your Google Drive and set up the project.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Project paths\n",
    "DRIVE_PROJECT = '/content/drive/MyDrive/research'\n",
    "LOCAL_PROJECT = '/content/research'\n",
    "\n",
    "# Clone or pull repository\n",
    "if not Path(LOCAL_PROJECT).exists():\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone https://github.com/Snehpatel101/research.git {LOCAL_PROJECT}\n",
    "else:\n",
    "    print(\"Pulling latest changes...\")\n",
    "    !cd {LOCAL_PROJECT} && git pull\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir(LOCAL_PROJECT)\n",
    "sys.path.insert(0, LOCAL_PROJECT)\n",
    "\n",
    "print(f\"\\nProject directory: {os.getcwd()}\")\n",
    "print(f\"Drive project: {DRIVE_PROJECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1.2 Install Dependencies { display-mode: \"form\" }\n",
    "#@markdown Installs all required packages for the ML pipeline.\n",
    "\n",
    "print(\"Installing dependencies...\")\n",
    "\n",
    "# Install the package\n",
    "!pip install -e . -q\n",
    "\n",
    "# Additional packages for Colab\n",
    "!pip install xgboost lightgbm catboost optuna -q\n",
    "\n",
    "# Verify PyTorch with CUDA\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"PyTorch: {torch.__version__} with CUDA {torch.version.cuda}\")\n",
    "else:\n",
    "    print(f\"PyTorch: {torch.__version__} (CPU only)\")\n",
    "\n",
    "print(\"\\nDependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1.3 Detect Hardware & Configure { display-mode: \"form\" }\n",
    "#@markdown Detects GPU and configures optimal settings.\n",
    "\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" HARDWARE DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# System info\n",
    "print(f\"\\nSystem: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "\n",
    "# GPU detection\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "GPU_NAME = None\n",
    "GPU_MEMORY = 0\n",
    "RECOMMENDED_BATCH_SIZE = 256\n",
    "MIXED_PRECISION = False\n",
    "\n",
    "if GPU_AVAILABLE:\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    GPU_NAME = props.name\n",
    "    GPU_MEMORY = props.total_memory / (1024**3)\n",
    "    \n",
    "    print(f\"\\nGPU: {GPU_NAME}\")\n",
    "    print(f\"Memory: {GPU_MEMORY:.1f} GB\")\n",
    "    print(f\"Compute Capability: {props.major}.{props.minor}\")\n",
    "    \n",
    "    # Set batch size based on memory\n",
    "    if GPU_MEMORY >= 40:  # A100\n",
    "        RECOMMENDED_BATCH_SIZE = 1024\n",
    "        MIXED_PRECISION = True\n",
    "    elif GPU_MEMORY >= 15:  # T4/V100\n",
    "        RECOMMENDED_BATCH_SIZE = 512\n",
    "        MIXED_PRECISION = True\n",
    "    else:\n",
    "        RECOMMENDED_BATCH_SIZE = 256\n",
    "        MIXED_PRECISION = props.major >= 7\n",
    "    \n",
    "    print(f\"\\nRecommended batch size: {RECOMMENDED_BATCH_SIZE}\")\n",
    "    print(f\"Mixed precision: {'Enabled' if MIXED_PRECISION else 'Disabled'}\")\n",
    "else:\n",
    "    print(\"\\nNo GPU detected - will use CPU\")\n",
    "    print(\"Tip: Runtime -> Change runtime type -> GPU\")\n",
    "\n",
    "# Verify model registry\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" AVAILABLE MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from src.models import ModelRegistry\n",
    "    models = ModelRegistry.list_models()\n",
    "    for family, model_list in models.items():\n",
    "        print(f\"\\n{family.upper()}:\")\n",
    "        for m in model_list:\n",
    "            gpu_req = \"GPU\" if m in ['lstm', 'gru', 'tcn'] else \"CPU\"\n",
    "            print(f\"  - {m} ({gpu_req})\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2.1 Check Raw Data Files { display-mode: \"form\" }\n",
    "#@markdown Verifies your OHLCV data files exist in Google Drive.\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_DATA_DIR = Path(DRIVE_PROJECT) / \"data\" / \"raw\"\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Looking for data in: {RAW_DATA_DIR}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find all data files\n",
    "parquet_files = list(RAW_DATA_DIR.glob(\"*.parquet\"))\n",
    "csv_files = list(RAW_DATA_DIR.glob(\"*.csv\"))\n",
    "all_files = parquet_files + csv_files\n",
    "\n",
    "AVAILABLE_SYMBOLS = []\n",
    "\n",
    "if all_files:\n",
    "    print(\"\\nFound data files:\")\n",
    "    for f in all_files:\n",
    "        try:\n",
    "            if f.suffix == '.parquet':\n",
    "                df = pd.read_parquet(f)\n",
    "            else:\n",
    "                df = pd.read_csv(f)\n",
    "            \n",
    "            # Extract symbol from filename\n",
    "            symbol = f.stem.split('_')[0].upper()\n",
    "            AVAILABLE_SYMBOLS.append(symbol)\n",
    "            \n",
    "            size_mb = f.stat().st_size / 1e6\n",
    "            print(f\"\\n  {f.name}\")\n",
    "            print(f\"    Symbol: {symbol}\")\n",
    "            print(f\"    Rows: {len(df):,}\")\n",
    "            print(f\"    Size: {size_mb:.1f} MB\")\n",
    "            print(f\"    Columns: {list(df.columns)}\")\n",
    "            if 'datetime' in df.columns or df.index.name == 'datetime':\n",
    "                if 'datetime' in df.columns:\n",
    "                    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "                    print(f\"    Date range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {f.name}: Error - {e}\")\n",
    "    \n",
    "    AVAILABLE_SYMBOLS = list(set(AVAILABLE_SYMBOLS))\n",
    "    print(f\"\\nAvailable symbols: {AVAILABLE_SYMBOLS}\")\n",
    "else:\n",
    "    print(\"\\nNo data files found!\")\n",
    "    print(\"\\nPlease upload your OHLCV data to:\")\n",
    "    print(f\"  {RAW_DATA_DIR}/\")\n",
    "    print(\"\\nExpected format:\")\n",
    "    print(\"  - MES_1m.parquet or MES_1m.csv\")\n",
    "    print(\"  - Columns: datetime, open, high, low, close, volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2.2 Create Directory Structure { display-mode: \"form\" }\n",
    "#@markdown Creates all required directories for the pipeline.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "directories = [\n",
    "    \"data/raw\",\n",
    "    \"data/clean\",\n",
    "    \"data/features\",\n",
    "    \"data/labels\",\n",
    "    \"data/final\",\n",
    "    \"data/splits/scaled\",\n",
    "    \"data/stacking\",\n",
    "    \"config/ga_results\",\n",
    "    \"runs\",\n",
    "    \"results\",\n",
    "    \"experiments/runs\",\n",
    "]\n",
    "\n",
    "print(\"Creating directories...\")\n",
    "for d in directories:\n",
    "    path = Path(DRIVE_PROJECT) / d\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"  {d}/\")\n",
    "\n",
    "print(\"\\nDirectory structure ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Phase 1: Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3.1 Configure Pipeline { display-mode: \"form\" }\n",
    "#@markdown Configure the data processing pipeline.\n",
    "\n",
    "#@markdown ### Symbol Selection\n",
    "symbols = \"MES\"  #@param {type: \"string\"}\n",
    "#@markdown Comma-separated symbols (e.g., \"MES,MGC\")\n",
    "\n",
    "#@markdown ### Timeframe\n",
    "target_timeframe = \"5min\"  #@param [\"5min\", \"10min\", \"15min\", \"30min\", \"1H\"]\n",
    "\n",
    "#@markdown ### Label Horizons\n",
    "horizons = \"5,10,15,20\"  #@param {type: \"string\"}\n",
    "#@markdown Comma-separated horizons (bars ahead)\n",
    "\n",
    "#@markdown ### Train/Val/Test Split\n",
    "train_ratio = 0.70  #@param {type: \"slider\", min: 0.5, max: 0.8, step: 0.05}\n",
    "val_ratio = 0.15  #@param {type: \"slider\", min: 0.1, max: 0.25, step: 0.05}\n",
    "\n",
    "# Parse inputs\n",
    "SYMBOLS = [s.strip().upper() for s in symbols.split(',')]\n",
    "HORIZONS = [int(h.strip()) for h in horizons.split(',')]\n",
    "TRAIN_RATIO = train_ratio\n",
    "VAL_RATIO = val_ratio\n",
    "TEST_RATIO = round(1.0 - train_ratio - val_ratio, 2)\n",
    "\n",
    "print(\"Pipeline Configuration:\")\n",
    "print(f\"  Symbols: {SYMBOLS}\")\n",
    "print(f\"  Timeframe: {target_timeframe}\")\n",
    "print(f\"  Horizons: {HORIZONS}\")\n",
    "print(f\"  Train/Val/Test: {TRAIN_RATIO}/{VAL_RATIO}/{TEST_RATIO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3.2 Run Data Pipeline { display-mode: \"form\" }\n",
    "#@markdown Executes the complete Phase 1 data pipeline.\n",
    "#@markdown This will take ~10-15 minutes for 40k samples.\n",
    "\n",
    "skip_if_exists = True  #@param {type: \"boolean\"}\n",
    "#@markdown Skip pipeline if processed data already exists\n",
    "\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Check if data already processed\n",
    "splits_dir = Path(DRIVE_PROJECT) / \"data\" / \"splits\" / \"scaled\"\n",
    "train_file = splits_dir / \"train_scaled.parquet\"\n",
    "\n",
    "if skip_if_exists and train_file.exists():\n",
    "    print(\"Processed data already exists!\")\n",
    "    print(f\"  Location: {splits_dir}\")\n",
    "    \n",
    "    import pandas as pd\n",
    "    train_df = pd.read_parquet(train_file)\n",
    "    print(f\"  Train samples: {len(train_df):,}\")\n",
    "    print(f\"  Features: {len([c for c in train_df.columns if not c.startswith('label_')])}\")\n",
    "    print(\"\\nSkipping pipeline. Uncheck 'skip_if_exists' to rerun.\")\n",
    "else:\n",
    "    print(\"Running Phase 1 Data Pipeline...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        from src.phase1.pipeline_config import PipelineConfig\n",
    "        from src.pipeline.runner import PipelineRunner\n",
    "        \n",
    "        config = PipelineConfig(\n",
    "            symbols=SYMBOLS,\n",
    "            project_root=Path(DRIVE_PROJECT),\n",
    "            target_timeframe=target_timeframe,\n",
    "            label_horizons=HORIZONS,\n",
    "            train_ratio=TRAIN_RATIO,\n",
    "            val_ratio=VAL_RATIO,\n",
    "            test_ratio=TEST_RATIO,\n",
    "        )\n",
    "        \n",
    "        runner = PipelineRunner(config)\n",
    "        success = runner.run()\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        if success:\n",
    "            print(f\"Pipeline completed in {elapsed/60:.1f} minutes!\")\n",
    "        else:\n",
    "            print(\"Pipeline failed. Check errors above.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3.3 Verify Processed Data { display-mode: \"form\" }\n",
    "#@markdown Loads and displays the processed datasets.\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "splits_dir = Path(DRIVE_PROJECT) / \"data\" / \"splits\" / \"scaled\"\n",
    "\n",
    "print(\"Loading processed datasets...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_parquet(splits_dir / \"train_scaled.parquet\")\n",
    "    val_df = pd.read_parquet(splits_dir / \"val_scaled.parquet\")\n",
    "    test_df = pd.read_parquet(splits_dir / \"test_scaled.parquet\")\n",
    "    \n",
    "    print(f\"\\nDataset sizes:\")\n",
    "    print(f\"  Train: {len(train_df):,} samples\")\n",
    "    print(f\"  Val:   {len(val_df):,} samples\")\n",
    "    print(f\"  Test:  {len(test_df):,} samples\")\n",
    "    print(f\"  Total: {len(train_df) + len(val_df) + len(test_df):,} samples\")\n",
    "    \n",
    "    # Count features\n",
    "    feature_cols = [c for c in train_df.columns if not c.startswith(('label_', 'sample_weight', 'quality_score', 'datetime', 'symbol'))]\n",
    "    label_cols = [c for c in train_df.columns if c.startswith('label_')]\n",
    "    \n",
    "    print(f\"\\nFeatures: {len(feature_cols)}\")\n",
    "    print(f\"Labels: {label_cols}\")\n",
    "    \n",
    "    # Label distribution\n",
    "    print(f\"\\nLabel distribution (train):\")\n",
    "    for col in label_cols:\n",
    "        dist = train_df[col].value_counts().sort_index()\n",
    "        print(f\"  {col}: Long={dist.get(1, 0):,} | Neutral={dist.get(0, 0):,} | Short={dist.get(-1, 0):,}\")\n",
    "    \n",
    "    # Store for later use\n",
    "    TRAIN_DF = train_df\n",
    "    VAL_DF = val_df\n",
    "    TEST_DF = test_df\n",
    "    FEATURE_COLS = feature_cols\n",
    "    \n",
    "    print(\"\\nData ready for model training!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Processed data not found. Run Section 3.2 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Phase 2: Model Training\n",
    "\n",
    "Choose between **Single Model** or **Multi-Model** training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4.1 Training Mode Selection { display-mode: \"form\" }\n",
    "#@markdown Choose your training mode and models.\n",
    "\n",
    "training_mode = \"Single Model\"  #@param [\"Single Model\", \"Multi-Model (Sequential)\", \"Multi-Model (Compare All)\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Single Model Options\n",
    "single_model = \"xgboost\"  #@param [\"xgboost\", \"lightgbm\", \"catboost\", \"random_forest\", \"logistic\", \"svm\", \"lstm\", \"gru\", \"tcn\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Multi-Model Options\n",
    "train_boosting = True  #@param {type: \"boolean\"}\n",
    "#@markdown XGBoost, LightGBM, CatBoost\n",
    "train_classical = False  #@param {type: \"boolean\"}\n",
    "#@markdown Random Forest, Logistic, SVM\n",
    "train_neural = False  #@param {type: \"boolean\"}\n",
    "#@markdown LSTM, GRU, TCN (requires GPU)\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Training Parameters\n",
    "horizon = 20  #@param [5, 10, 15, 20]\n",
    "sequence_length = 60  #@param {type: \"slider\", min: 30, max: 120, step: 10}\n",
    "#@markdown Sequence length for neural models\n",
    "\n",
    "# Build model list\n",
    "if training_mode == \"Single Model\":\n",
    "    MODELS_TO_TRAIN = [single_model]\n",
    "elif training_mode == \"Multi-Model (Compare All)\":\n",
    "    MODELS_TO_TRAIN = []\n",
    "    if train_boosting:\n",
    "        MODELS_TO_TRAIN.extend(['xgboost', 'lightgbm', 'catboost'])\n",
    "    if train_classical:\n",
    "        MODELS_TO_TRAIN.extend(['random_forest', 'logistic', 'svm'])\n",
    "    if train_neural and GPU_AVAILABLE:\n",
    "        MODELS_TO_TRAIN.extend(['lstm', 'gru', 'tcn'])\n",
    "    elif train_neural and not GPU_AVAILABLE:\n",
    "        print(\"WARNING: Neural models skipped (no GPU)\")\n",
    "else:\n",
    "    MODELS_TO_TRAIN = []\n",
    "    if train_boosting:\n",
    "        MODELS_TO_TRAIN.extend(['xgboost', 'lightgbm', 'catboost'])\n",
    "    if train_classical:\n",
    "        MODELS_TO_TRAIN.extend(['random_forest', 'logistic', 'svm'])\n",
    "    if train_neural and GPU_AVAILABLE:\n",
    "        MODELS_TO_TRAIN.extend(['lstm', 'gru', 'tcn'])\n",
    "\n",
    "HORIZON = horizon\n",
    "SEQ_LEN = sequence_length\n",
    "\n",
    "print(f\"Training Mode: {training_mode}\")\n",
    "print(f\"Models to train: {MODELS_TO_TRAIN}\")\n",
    "print(f\"Horizon: H{HORIZON}\")\n",
    "if any(m in ['lstm', 'gru', 'tcn'] for m in MODELS_TO_TRAIN):\n",
    "    print(f\"Sequence length: {SEQ_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 4.2 Train Models { display-mode: \"form\" }\n#@markdown Execute model training based on your selections.\n\nimport time\nfrom pathlib import Path\n\nprint(\"=\" * 60)\nprint(\" MODEL TRAINING\")\nprint(\"=\" * 60)\n\n# Results storage\nTRAINING_RESULTS = {}\n\ntry:\n    from src.models import ModelRegistry, Trainer, TrainerConfig\n    from src.phase1.stages.datasets.container import TimeSeriesDataContainer\n    \n    # Load data container\n    print(f\"\\nLoading data for horizon H{HORIZON}...\")\n    container = TimeSeriesDataContainer.from_parquet_dir(\n        path=Path(DRIVE_PROJECT) / \"data\" / \"splits\" / \"scaled\",\n        horizon=HORIZON\n    )\n    print(f\"  Train samples: {container.splits['train'].n_samples:,}\")\n    print(f\"  Val samples: {container.splits['val'].n_samples:,}\")\n    print(f\"  Features: {container.n_features}\")\n    \n    # Train each model\n    for i, model_name in enumerate(MODELS_TO_TRAIN, 1):\n        print(f\"\\n{'='*60}\")\n        print(f\" [{i}/{len(MODELS_TO_TRAIN)}] Training: {model_name.upper()}\")\n        print(\"=\" * 60)\n        \n        start_time = time.time()\n        \n        # Configure based on model type\n        model_config = {}\n        if model_name in ['lstm', 'gru', 'tcn']:\n            config = TrainerConfig(\n                model_name=model_name,\n                horizon=HORIZON,\n                sequence_length=SEQ_LEN,\n                batch_size=RECOMMENDED_BATCH_SIZE,\n                max_epochs=50,\n                early_stopping_patience=10,\n                output_dir=Path(DRIVE_PROJECT) / \"experiments\" / \"runs\",\n                device=\"cuda\" if GPU_AVAILABLE else \"cpu\",\n                mixed_precision=MIXED_PRECISION,\n            )\n        else:\n            config = TrainerConfig(\n                model_name=model_name,\n                horizon=HORIZON,\n                output_dir=Path(DRIVE_PROJECT) / \"experiments\" / \"runs\",\n            )\n        \n        # Train\n        trainer = Trainer(config)\n        results = trainer.run(container)\n        \n        elapsed = time.time() - start_time\n        \n        # Store results\n        TRAINING_RESULTS[model_name] = {\n            'metrics': results.get('evaluation_metrics', {}),\n            'time': elapsed,\n            'run_id': results.get('run_id', 'unknown'),\n        }\n        \n        # Display results\n        metrics = results.get('evaluation_metrics', {})\n        print(f\"\\n  Results:\")\n        print(f\"    Accuracy: {metrics.get('accuracy', 0):.2%}\")\n        print(f\"    Macro F1: {metrics.get('macro_f1', 0):.4f}\")\n        print(f\"    Time: {elapsed:.1f}s\")\n        \nexcept Exception as e:\n    print(f\"\\nError during training: {e}\")\n    import traceback\n    traceback.print_exc()\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\" TRAINING COMPLETE\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4.3 Compare Results { display-mode: \"form\" }\n",
    "#@markdown Display comparison of all trained models.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if TRAINING_RESULTS:\n",
    "    print(\"Model Comparison\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Build comparison table\n",
    "    rows = []\n",
    "    for model, data in TRAINING_RESULTS.items():\n",
    "        metrics = data['metrics']\n",
    "        rows.append({\n",
    "            'Model': model,\n",
    "            'Accuracy': metrics.get('accuracy', 0),\n",
    "            'Macro F1': metrics.get('macro_f1', 0),\n",
    "            'Weighted F1': metrics.get('weighted_f1', 0),\n",
    "            'Time (s)': data['time'],\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(rows)\n",
    "    comparison_df = comparison_df.sort_values('Macro F1', ascending=False)\n",
    "    \n",
    "    # Display table\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Plot if multiple models\n",
    "    if len(TRAINING_RESULTS) > 1:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        # Accuracy bar chart\n",
    "        comparison_df_sorted = comparison_df.sort_values('Accuracy', ascending=True)\n",
    "        axes[0].barh(comparison_df_sorted['Model'], comparison_df_sorted['Accuracy'])\n",
    "        axes[0].set_xlabel('Accuracy')\n",
    "        axes[0].set_title('Model Accuracy Comparison')\n",
    "        axes[0].set_xlim(0, 1)\n",
    "        \n",
    "        # Training time bar chart\n",
    "        comparison_df_sorted = comparison_df.sort_values('Time (s)', ascending=True)\n",
    "        axes[1].barh(comparison_df_sorted['Model'], comparison_df_sorted['Time (s)'])\n",
    "        axes[1].set_xlabel('Training Time (seconds)')\n",
    "        axes[1].set_title('Training Time Comparison')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Best model\n",
    "    best_model = comparison_df.iloc[0]['Model']\n",
    "    print(f\"\\nBest model: {best_model}\")\n",
    "else:\n",
    "    print(\"No training results yet. Run Section 4.2 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Phase 3: Cross-Validation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5.1 Run Cross-Validation { display-mode: \"form\" }\n",
    "#@markdown Run purged k-fold cross-validation for robust evaluation.\n",
    "\n",
    "run_cv = False  #@param {type: \"boolean\"}\n",
    "cv_model = \"xgboost\"  #@param [\"xgboost\", \"lightgbm\", \"catboost\", \"random_forest\"]\n",
    "n_splits = 5  #@param {type: \"slider\", min: 3, max: 10, step: 1}\n",
    "\n",
    "if run_cv:\n",
    "    print(f\"Running {n_splits}-fold cross-validation for {cv_model}...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    !python scripts/run_cv.py \\\n",
    "        --models {cv_model} \\\n",
    "        --horizons {HORIZON} \\\n",
    "        --n-splits {n_splits} \\\n",
    "        --data-dir {DRIVE_PROJECT}/data/splits/scaled \\\n",
    "        --output-dir {DRIVE_PROJECT}/results/cv\n",
    "else:\n",
    "    print(\"Cross-validation skipped. Enable 'run_cv' to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Phase 4: Ensemble Training (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6.1 Train Ensemble { display-mode: \"form\" }\n",
    "#@markdown Combine multiple models into an ensemble.\n",
    "\n",
    "train_ensemble = False  #@param {type: \"boolean\"}\n",
    "ensemble_type = \"voting\"  #@param [\"voting\", \"stacking\", \"blending\"]\n",
    "base_models = \"xgboost,lightgbm,catboost\"  #@param {type: \"string\"}\n",
    "\n",
    "if train_ensemble:\n",
    "    print(f\"Training {ensemble_type} ensemble...\")\n",
    "    print(f\"Base models: {base_models}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        from src.models import ModelRegistry, Trainer, TrainerConfig\n",
    "        from src.phase1.stages.datasets.container import TimeSeriesDataContainer\n",
    "        \n",
    "        container = TimeSeriesDataContainer.from_parquet_dir(\n",
    "            path=Path(DRIVE_PROJECT) / \"data\" / \"splits\" / \"scaled\",\n",
    "            horizon=HORIZON\n",
    "        )\n",
    "        \n",
    "        config = TrainerConfig(\n",
    "            model_name=ensemble_type,\n",
    "            horizon=HORIZON,\n",
    "            output_dir=Path(DRIVE_PROJECT) / \"experiments\" / \"runs\",\n",
    "            model_config={\n",
    "                \"base_model_names\": [m.strip() for m in base_models.split(',')],\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(config)\n",
    "        results = trainer.run(container)\n",
    "        \n",
    "        metrics = results.get('evaluation_metrics', {})\n",
    "        print(f\"\\nEnsemble Results:\")\n",
    "        print(f\"  Accuracy: {metrics.get('accuracy', 0):.2%}\")\n",
    "        print(f\"  Macro F1: {metrics.get('macro_f1', 0):.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"Ensemble training skipped. Enable 'train_ensemble' to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Save Results & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 7.1 Summary & Saved Artifacts { display-mode: \"form\" }\n",
    "#@markdown Display summary and location of all saved files.\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" SESSION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Data summary\n",
    "print(\"\\n DATA:\")\n",
    "splits_dir = Path(DRIVE_PROJECT) / \"data\" / \"splits\" / \"scaled\"\n",
    "if splits_dir.exists():\n",
    "    for f in splits_dir.glob(\"*.parquet\"):\n",
    "        size_mb = f.stat().st_size / 1e6\n",
    "        print(f\"  {f.name}: {size_mb:.1f} MB\")\n",
    "\n",
    "# Training results\n",
    "print(\"\\n TRAINED MODELS:\")\n",
    "experiments_dir = Path(DRIVE_PROJECT) / \"experiments\" / \"runs\"\n",
    "if experiments_dir.exists():\n",
    "    runs = list(experiments_dir.iterdir())\n",
    "    for run_dir in sorted(runs)[-5:]:  # Last 5 runs\n",
    "        if run_dir.is_dir():\n",
    "            print(f\"  {run_dir.name}\")\n",
    "\n",
    "# Next steps\n",
    "print(\"\\n NEXT STEPS:\")\n",
    "print(\"  1. Review model metrics in experiments/runs/\")\n",
    "print(\"  2. Try different model configurations\")\n",
    "print(\"  3. Run cross-validation for robust evaluation\")\n",
    "print(\"  4. Train ensemble for best performance\")\n",
    "print(\"  5. Export best model for production\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\" Results saved to: {DRIVE_PROJECT}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 7.2 Quick Test: Load Trained Model { display-mode: \"form\" }\n",
    "#@markdown Load a trained model and make predictions.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "experiments_dir = Path(DRIVE_PROJECT) / \"experiments\" / \"runs\"\n",
    "\n",
    "if experiments_dir.exists():\n",
    "    runs = sorted([d for d in experiments_dir.iterdir() if d.is_dir()])\n",
    "    \n",
    "    if runs:\n",
    "        latest_run = runs[-1]\n",
    "        print(f\"Latest run: {latest_run.name}\")\n",
    "        \n",
    "        # List contents\n",
    "        for item in latest_run.rglob(\"*\"):\n",
    "            if item.is_file():\n",
    "                rel_path = item.relative_to(latest_run)\n",
    "                size = item.stat().st_size / 1024\n",
    "                print(f\"  {rel_path}: {size:.1f} KB\")\n",
    "    else:\n",
    "        print(\"No training runs found.\")\n",
    "else:\n",
    "    print(\"Experiments directory not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix: Quick Commands\n",
    "\n",
    "```bash\n",
    "# Train single model\n",
    "!python scripts/train_model.py --model xgboost --horizon 20\n",
    "\n",
    "# Train neural model\n",
    "!python scripts/train_model.py --model lstm --horizon 20 --seq-len 60\n",
    "\n",
    "# Run cross-validation\n",
    "!python scripts/run_cv.py --models xgboost,lightgbm --horizons 20 --n-splits 5\n",
    "\n",
    "# Train ensemble\n",
    "!python scripts/train_model.py --model voting --horizon 20\n",
    "\n",
    "# List all models\n",
    "!python scripts/train_model.py --list-models\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}