{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model Factory - Complete Pipeline & Training\n",
    "\n",
    "This notebook runs the **complete ML pipeline** from raw data to trained models.\n",
    "\n",
    "## What This Notebook Does\n",
    "1. **Setup** - Mount Drive (for results), clone GitHub repo (for code & data)\n",
    "2. **Phase 1** - Data pipeline (clean -> features -> labels -> splits)\n",
    "3. **Phase 2** - Model training (single or multiple models)\n",
    "4. **Phase 3** - Cross-validation (optional)\n",
    "5. **Phase 4** - Ensemble training (optional)\n",
    "\n",
    "## Data Flow\n",
    "- **Data Source:** `/content/research/` (cloned from GitHub)\n",
    "- **Results Saved:** `/content/drive/MyDrive/research/` (Google Drive for persistence)\n",
    "\n",
    "## Quick Start\n",
    "1. Run cells in order (or use Runtime -> Run all)\n",
    "2. Data is loaded from the GitHub clone\n",
    "3. Results are saved to Google Drive for persistence\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 1.1 Mount Google Drive & Clone Repository { display-mode: \"form\" }\n",
    "#@markdown Run this cell to mount your Google Drive and set up the project.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Mount Google Drive (for saving results only)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Clone or pull repository\n",
    "if not Path('/content/research').exists():\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone https://github.com/Snehpatel101/research.git /content/research\n",
    "else:\n",
    "    print(\"Pulling latest changes...\")\n",
    "    !cd /content/research && git pull\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir('/content/research')\n",
    "\n",
    "# Create Drive directories for saving results\n",
    "for d in [\"experiments/runs\", \"results\"]:\n",
    "    Path('/content/drive/MyDrive/research', d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" PATH CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nProject directory: {os.getcwd()}\")\n",
    "print(f\"Data source: /content/research (from GitHub)\")\n",
    "print(f\"Results saved to: /content/drive/MyDrive/research (Google Drive)\")\n",
    "print(\"=\" * 60)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 1.2 Install Dependencies { display-mode: \"form\" }\n",
    "#@markdown Installs all required packages for the ML pipeline.\n",
    "\n",
    "import sys\n",
    "\n",
    "# Add project to Python path\n",
    "sys.path.insert(0, '/content/research')\n",
    "\n",
    "# Install required packages\n",
    "!pip install xgboost lightgbm catboost optuna ta pywavelets scikit-learn pandas numpy -q\n",
    "\n",
    "# Verify PyTorch with CUDA\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"PyTorch: {torch.__version__} with CUDA {torch.version.cuda}\")\n",
    "else:\n",
    "    print(f\"PyTorch: {torch.__version__} (CPU only)\")\n",
    "\n",
    "print(f\"\\nProject path added: /content/research\")\n",
    "print(\"Dependencies installed!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 1.3 Detect Hardware & Configure { display-mode: \"form\" }\n",
    "#@markdown Detects GPU and configures optimal settings.\n",
    "\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" HARDWARE DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# System info\n",
    "print(f\"\\nSystem: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "\n",
    "# GPU detection\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "GPU_NAME = None\n",
    "GPU_MEMORY = 0\n",
    "RECOMMENDED_BATCH_SIZE = 256\n",
    "MIXED_PRECISION = False\n",
    "\n",
    "if GPU_AVAILABLE:\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    GPU_NAME = props.name\n",
    "    GPU_MEMORY = props.total_memory / (1024**3)\n",
    "    \n",
    "    print(f\"\\nGPU: {GPU_NAME}\")\n",
    "    print(f\"Memory: {GPU_MEMORY:.1f} GB\")\n",
    "    print(f\"Compute Capability: {props.major}.{props.minor}\")\n",
    "    \n",
    "    if GPU_MEMORY >= 40:  # A100\n",
    "        RECOMMENDED_BATCH_SIZE = 1024\n",
    "        MIXED_PRECISION = True\n",
    "    elif GPU_MEMORY >= 15:  # T4/V100\n",
    "        RECOMMENDED_BATCH_SIZE = 512\n",
    "        MIXED_PRECISION = True\n",
    "    else:\n",
    "        RECOMMENDED_BATCH_SIZE = 256\n",
    "        MIXED_PRECISION = props.major >= 7\n",
    "    \n",
    "    print(f\"\\nRecommended batch size: {RECOMMENDED_BATCH_SIZE}\")\n",
    "    print(f\"Mixed precision: {'Enabled' if MIXED_PRECISION else 'Disabled'}\")\n",
    "else:\n",
    "    print(\"\\nNo GPU detected - will use CPU\")\n",
    "    print(\"Tip: Runtime -> Change runtime type -> GPU\")\n",
    "\n",
    "# Verify model registry\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" AVAILABLE MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from src.models import ModelRegistry\n",
    "    models = ModelRegistry.list_models()\n",
    "    for family, model_list in models.items():\n",
    "        print(f\"\\n{family.upper()}:\")\n",
    "        for m in model_list:\n",
    "            gpu_req = \"GPU\" if m in ['lstm', 'gru', 'tcn'] else \"CPU\"\n",
    "            print(f\"  - {m} ({gpu_req})\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Phase 1: Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 3.1 Configure Pipeline { display-mode: \"form\" }\n",
    "#@markdown Configure the data processing pipeline.\n",
    "\n",
    "#@markdown ### Symbol Selection\n",
    "symbols = \"MES\"  #@param {type: \"string\"}\n",
    "#@markdown Comma-separated symbols (e.g., \"MES,MGC\")\n",
    "\n",
    "#@markdown ### Label Horizons\n",
    "horizons = \"5,10,15,20\"  #@param {type: \"string\"}\n",
    "#@markdown Comma-separated horizons (bars ahead)\n",
    "\n",
    "#@markdown ### Train/Val/Test Split\n",
    "train_ratio = 0.70  #@param {type: \"slider\", min: 0.5, max: 0.8, step: 0.05}\n",
    "val_ratio = 0.15  #@param {type: \"slider\", min: 0.1, max: 0.25, step: 0.05}\n",
    "\n",
    "# Parse inputs\n",
    "SYMBOLS = [s.strip().upper() for s in symbols.split(',')]\n",
    "HORIZONS = [int(h.strip()) for h in horizons.split(',')]\n",
    "TRAIN_RATIO = train_ratio\n",
    "VAL_RATIO = val_ratio\n",
    "TEST_RATIO = round(1.0 - train_ratio - val_ratio, 2)\n",
    "\n",
    "print(\"Pipeline Configuration:\")\n",
    "print(f\"  Symbols: {SYMBOLS}\")\n",
    "print(f\"  Horizons: {HORIZONS}\")\n",
    "print(f\"  Train/Val/Test: {TRAIN_RATIO}/{VAL_RATIO}/{TEST_RATIO}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 3.2 Run Data Pipeline OR Use Existing Data { display-mode: \"form\" }\n",
    "#@markdown Choose whether to run the full pipeline or use existing processed data.\n",
    "\n",
    "data_source = \"Use existing processed data\"  #@param [\"Run full pipeline (requires raw data)\", \"Use existing processed data\"]\n",
    "\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# CORRECT: Data from GitHub clone (not Google Drive)\n",
    "splits_dir = Path('/content/research/data/splits/scaled')\n",
    "train_file = splits_dir / \"train_scaled.parquet\"\n",
    "\n",
    "if data_source == \"Use existing processed data\":\n",
    "    if train_file.exists():\n",
    "        import pandas as pd\n",
    "        train_df = pd.read_parquet(train_file)\n",
    "        val_df = pd.read_parquet(splits_dir / \"val_scaled.parquet\")\n",
    "        test_df = pd.read_parquet(splits_dir / \"test_scaled.parquet\")\n",
    "        \n",
    "        print(\"Found existing processed data!\")\n",
    "        print(f\"  Location: {splits_dir}\")\n",
    "        print(f\"  Train: {len(train_df):,} samples\")\n",
    "        print(f\"  Val: {len(val_df):,} samples\")\n",
    "        print(f\"  Test: {len(test_df):,} samples\")\n",
    "        print(\"\\nSkipping pipeline - proceeding to model training!\")\n",
    "    else:\n",
    "        print(\"ERROR: Processed data not found!\")\n",
    "        print(f\"  Expected: {splits_dir}/\")\n",
    "        print(\"\\nMake sure the GitHub repo contains processed data files:\")\n",
    "        print(\"  - train_scaled.parquet\")\n",
    "        print(\"  - val_scaled.parquet\")\n",
    "        print(\"  - test_scaled.parquet\")\n",
    "else:\n",
    "    raw_dir = Path('/content/research/data/raw')\n",
    "    raw_files = list(raw_dir.glob(\"*.parquet\")) + list(raw_dir.glob(\"*.csv\")) if raw_dir.exists() else []\n",
    "    \n",
    "    if not raw_files:\n",
    "        print(\"ERROR: No raw data files found!\")\n",
    "        print(f\"  Expected: {raw_dir}/MES_1m.parquet or .csv\")\n",
    "    else:\n",
    "        print(\"Running Phase 1 Data Pipeline...\")\n",
    "        print(\"=\" * 60)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            from src.phase1.pipeline_config import PipelineConfig\n",
    "            from src.pipeline.runner import PipelineRunner\n",
    "            \n",
    "            config = PipelineConfig(\n",
    "                symbols=SYMBOLS,\n",
    "                project_root=Path('/content/research'),\n",
    "                label_horizons=HORIZONS,\n",
    "                train_ratio=TRAIN_RATIO,\n",
    "                val_ratio=VAL_RATIO,\n",
    "                test_ratio=TEST_RATIO,\n",
    "            )\n",
    "            \n",
    "            runner = PipelineRunner(config)\n",
    "            success = runner.run()\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            if success:\n",
    "                print(f\"Pipeline completed in {elapsed/60:.1f} minutes!\")\n",
    "            else:\n",
    "                print(\"Pipeline failed. Check errors above.\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 3.3 Verify Processed Data { display-mode: \"form\" }\n",
    "#@markdown Loads and displays the processed datasets.\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# CORRECT: Data from GitHub clone (not Google Drive)\n",
    "splits_dir = Path('/content/research/data/splits/scaled')\n",
    "\n",
    "print(\"Loading processed datasets...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_parquet(splits_dir / \"train_scaled.parquet\")\n",
    "    val_df = pd.read_parquet(splits_dir / \"val_scaled.parquet\")\n",
    "    test_df = pd.read_parquet(splits_dir / \"test_scaled.parquet\")\n",
    "    \n",
    "    print(f\"\\nDataset sizes:\")\n",
    "    print(f\"  Train: {len(train_df):,} samples\")\n",
    "    print(f\"  Val:   {len(val_df):,} samples\")\n",
    "    print(f\"  Test:  {len(test_df):,} samples\")\n",
    "    print(f\"  Total: {len(train_df) + len(val_df) + len(test_df):,} samples\")\n",
    "    \n",
    "    feature_cols = [c for c in train_df.columns if not c.startswith(('label_', 'sample_weight', 'quality_score', 'datetime', 'symbol'))]\n",
    "    label_cols = [c for c in train_df.columns if c.startswith('label_')]\n",
    "    \n",
    "    print(f\"\\nFeatures: {len(feature_cols)}\")\n",
    "    print(f\"Labels: {label_cols}\")\n",
    "    \n",
    "    print(f\"\\nLabel distribution (train):\")\n",
    "    for col in label_cols:\n",
    "        dist = train_df[col].value_counts().sort_index()\n",
    "        print(f\"  {col}: Long={dist.get(1, 0):,} | Neutral={dist.get(0, 0):,} | Short={dist.get(-1, 0):,}\")\n",
    "    \n",
    "    TRAIN_DF = train_df\n",
    "    VAL_DF = val_df\n",
    "    TEST_DF = test_df\n",
    "    FEATURE_COLS = feature_cols\n",
    "    \n",
    "    print(\"\\nData ready for model training!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Processed data not found. Run Section 3.2 first.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Phase 2: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 4.1 Training Mode Selection { display-mode: \"form\" }\n",
    "#@markdown Choose your training mode and models.\n",
    "\n",
    "training_mode = \"Single Model\"  #@param [\"Single Model\", \"Multi-Model (Sequential)\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Single Model Options\n",
    "single_model = \"xgboost\"  #@param [\"xgboost\", \"lightgbm\", \"catboost\", \"random_forest\", \"logistic\", \"svm\", \"lstm\", \"gru\", \"tcn\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Multi-Model Options\n",
    "train_boosting = True  #@param {type: \"boolean\"}\n",
    "#@markdown XGBoost, LightGBM, CatBoost\n",
    "train_classical = False  #@param {type: \"boolean\"}\n",
    "#@markdown Random Forest, Logistic, SVM\n",
    "train_neural = False  #@param {type: \"boolean\"}\n",
    "#@markdown LSTM, GRU, TCN (requires GPU)\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Training Parameters\n",
    "horizon = 20  #@param [5, 10, 15, 20]\n",
    "sequence_length = 60  #@param {type: \"slider\", min: 30, max: 120, step: 10}\n",
    "\n",
    "# Build model list\n",
    "if training_mode == \"Single Model\":\n",
    "    MODELS_TO_TRAIN = [single_model]\n",
    "else:\n",
    "    MODELS_TO_TRAIN = []\n",
    "    if train_boosting:\n",
    "        MODELS_TO_TRAIN.extend(['xgboost', 'lightgbm', 'catboost'])\n",
    "    if train_classical:\n",
    "        MODELS_TO_TRAIN.extend(['random_forest', 'logistic', 'svm'])\n",
    "    if train_neural and GPU_AVAILABLE:\n",
    "        MODELS_TO_TRAIN.extend(['lstm', 'gru', 'tcn'])\n",
    "    elif train_neural and not GPU_AVAILABLE:\n",
    "        print(\"WARNING: Neural models skipped (no GPU)\")\n",
    "\n",
    "HORIZON = horizon\n",
    "SEQ_LEN = sequence_length\n",
    "\n",
    "print(f\"Training Mode: {training_mode}\")\n",
    "print(f\"Models to train: {MODELS_TO_TRAIN}\")\n",
    "print(f\"Horizon: H{HORIZON}\")\n",
    "if any(m in ['lstm', 'gru', 'tcn'] for m in MODELS_TO_TRAIN):\n",
    "    print(f\"Sequence length: {SEQ_LEN}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 4.2 Train Models { display-mode: \"form\" }\n",
    "#@markdown Execute model training based on your selections.\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" MODEL TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "TRAINING_RESULTS = {}\n",
    "\n",
    "try:\n",
    "    from src.models import ModelRegistry, Trainer, TrainerConfig\n",
    "    from src.phase1.stages.datasets.container import TimeSeriesDataContainer\n",
    "    \n",
    "    # CORRECT: Load data from GitHub clone (not Google Drive)\n",
    "    print(f\"\\nLoading data for horizon H{HORIZON}...\")\n",
    "    container = TimeSeriesDataContainer.from_parquet_dir(\n",
    "        path=Path('/content/research/data/splits/scaled'),\n",
    "        horizon=HORIZON\n",
    "    )\n",
    "    print(f\"  Train samples: {container.splits['train'].n_samples:,}\")\n",
    "    print(f\"  Val samples: {container.splits['val'].n_samples:,}\")\n",
    "    print(f\"  Features: {container.n_features}\")\n",
    "    \n",
    "    for i, model_name in enumerate(MODELS_TO_TRAIN, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\" [{i}/{len(MODELS_TO_TRAIN)}] Training: {model_name.upper()}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Configure - save results to Google Drive\n",
    "        if model_name in ['lstm', 'gru', 'tcn']:\n",
    "            config = TrainerConfig(\n",
    "                model_name=model_name,\n",
    "                horizon=HORIZON,\n",
    "                sequence_length=SEQ_LEN,\n",
    "                batch_size=RECOMMENDED_BATCH_SIZE,\n",
    "                max_epochs=50,\n",
    "                early_stopping_patience=10,\n",
    "                output_dir=Path('/content/drive/MyDrive/research/experiments/runs'),\n",
    "                device=\"cuda\" if GPU_AVAILABLE else \"cpu\",\n",
    "                mixed_precision=MIXED_PRECISION,\n",
    "            )\n",
    "        else:\n",
    "            config = TrainerConfig(\n",
    "                model_name=model_name,\n",
    "                horizon=HORIZON,\n",
    "                output_dir=Path('/content/drive/MyDrive/research/experiments/runs'),\n",
    "            )\n",
    "        \n",
    "        trainer = Trainer(config)\n",
    "        results = trainer.run(container)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        TRAINING_RESULTS[model_name] = {\n",
    "            'metrics': results.get('evaluation_metrics', {}),\n",
    "            'time': elapsed,\n",
    "            'run_id': results.get('run_id', 'unknown'),\n",
    "        }\n",
    "        \n",
    "        metrics = results.get('evaluation_metrics', {})\n",
    "        print(f\"\\n  Results:\")\n",
    "        print(f\"    Accuracy: {metrics.get('accuracy', 0):.2%}\")\n",
    "        print(f\"    Macro F1: {metrics.get('macro_f1', 0):.4f}\")\n",
    "        print(f\"    Time: {elapsed:.1f}s\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nError during training: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" TRAINING COMPLETE\")\n",
    "print(\"=\" * 60)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 4.3 Compare Results { display-mode: \"form\" }\n",
    "#@markdown Display comparison of all trained models.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if TRAINING_RESULTS:\n",
    "    print(\"Model Comparison\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    rows = []\n",
    "    for model, data in TRAINING_RESULTS.items():\n",
    "        metrics = data['metrics']\n",
    "        rows.append({\n",
    "            'Model': model,\n",
    "            'Accuracy': metrics.get('accuracy', 0),\n",
    "            'Macro F1': metrics.get('macro_f1', 0),\n",
    "            'Weighted F1': metrics.get('weighted_f1', 0),\n",
    "            'Time (s)': data['time'],\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(rows)\n",
    "    comparison_df = comparison_df.sort_values('Macro F1', ascending=False)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    if len(TRAINING_RESULTS) > 1:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        comparison_df_sorted = comparison_df.sort_values('Accuracy', ascending=True)\n",
    "        axes[0].barh(comparison_df_sorted['Model'], comparison_df_sorted['Accuracy'])\n",
    "        axes[0].set_xlabel('Accuracy')\n",
    "        axes[0].set_title('Model Accuracy Comparison')\n",
    "        axes[0].set_xlim(0, 1)\n",
    "        \n",
    "        comparison_df_sorted = comparison_df.sort_values('Time (s)', ascending=True)\n",
    "        axes[1].barh(comparison_df_sorted['Model'], comparison_df_sorted['Time (s)'])\n",
    "        axes[1].set_xlabel('Training Time (seconds)')\n",
    "        axes[1].set_title('Training Time Comparison')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    best_model = comparison_df.iloc[0]['Model']\n",
    "    print(f\"\\nBest model: {best_model}\")\n",
    "else:\n",
    "    print(\"No training results yet. Run Section 4.2 first.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Phase 3: Cross-Validation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 5.1 Run Cross-Validation { display-mode: \"form\" }\n",
    "#@markdown Run purged k-fold cross-validation for robust evaluation.\n",
    "\n",
    "run_cv = False  #@param {type: \"boolean\"}\n",
    "cv_model = \"xgboost\"  #@param [\"xgboost\", \"lightgbm\", \"catboost\", \"random_forest\"]\n",
    "n_splits = 5  #@param {type: \"slider\", min: 3, max: 10, step: 1}\n",
    "\n",
    "if run_cv:\n",
    "    print(f\"Running {n_splits}-fold cross-validation for {cv_model}...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # CORRECT: Data from GitHub clone, results to Google Drive\n",
    "    !python scripts/run_cv.py \\\n",
    "        --models {cv_model} \\\n",
    "        --horizons {HORIZON} \\\n",
    "        --n-splits {n_splits} \\\n",
    "        --data-dir /content/research/data/splits/scaled \\\n",
    "        --output-dir /content/drive/MyDrive/research/results/cv\n",
    "else:\n",
    "    print(\"Cross-validation skipped. Enable run_cv to run.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Phase 4: Ensemble Training (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 6.1 Train Ensemble { display-mode: \"form\" }\n",
    "#@markdown Combine multiple models into an ensemble.\n",
    "\n",
    "train_ensemble = False  #@param {type: \"boolean\"}\n",
    "ensemble_type = \"voting\"  #@param [\"voting\", \"stacking\", \"blending\"]\n",
    "base_models = \"xgboost,lightgbm,catboost\"  #@param {type: \"string\"}\n",
    "\n",
    "if train_ensemble:\n",
    "    print(f\"Training {ensemble_type} ensemble...\")\n",
    "    print(f\"Base models: {base_models}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        from src.models import ModelRegistry, Trainer, TrainerConfig\n",
    "        from src.phase1.stages.datasets.container import TimeSeriesDataContainer\n",
    "        \n",
    "        # CORRECT: Load data from GitHub clone (not Google Drive)\n",
    "        container = TimeSeriesDataContainer.from_parquet_dir(\n",
    "            path=Path('/content/research/data/splits/scaled'),\n",
    "            horizon=HORIZON\n",
    "        )\n",
    "        \n",
    "        # Save results to Google Drive\n",
    "        config = TrainerConfig(\n",
    "            model_name=ensemble_type,\n",
    "            horizon=HORIZON,\n",
    "            output_dir=Path('/content/drive/MyDrive/research/experiments/runs'),\n",
    "            model_config={\n",
    "                \"base_model_names\": [m.strip() for m in base_models.split(',')],\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(config)\n",
    "        results = trainer.run(container)\n",
    "        \n",
    "        metrics = results.get('evaluation_metrics', {})\n",
    "        print(f\"\\nEnsemble Results:\")\n",
    "        print(f\"  Accuracy: {metrics.get('accuracy', 0):.2%}\")\n",
    "        print(f\"  Macro F1: {metrics.get('macro_f1', 0):.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"Ensemble training skipped. Enable train_ensemble to run.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Save Results & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 7.1 Summary & Saved Artifacts { display-mode: \"form\" }\n",
    "#@markdown Display summary and location of all saved files.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" SESSION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Data summary\n",
    "print(\"\\n DATA (from GitHub clone):\")\n",
    "splits_dir = Path('/content/research/data/splits/scaled')\n",
    "if splits_dir.exists():\n",
    "    for f in splits_dir.glob(\"*.parquet\"):\n",
    "        size_mb = f.stat().st_size / 1e6\n",
    "        print(f\"  {f.name}: {size_mb:.1f} MB\")\n",
    "\n",
    "# Training results\n",
    "print(\"\\n TRAINED MODELS (saved to Google Drive):\")\n",
    "experiments_dir = Path('/content/drive/MyDrive/research/experiments/runs')\n",
    "if experiments_dir.exists():\n",
    "    runs = list(experiments_dir.iterdir())\n",
    "    for run_dir in sorted(runs)[-5:]:\n",
    "        if run_dir.is_dir():\n",
    "            print(f\"  {run_dir.name}\")\n",
    "\n",
    "# Next steps\n",
    "print(\"\\n NEXT STEPS:\")\n",
    "print(\"  1. Review model metrics in Google Drive: experiments/runs/\")\n",
    "print(\"  2. Try different model configurations\")\n",
    "print(\"  3. Run cross-validation for robust evaluation\")\n",
    "print(\"  4. Train ensemble for best performance\")\n",
    "print(\"  5. Export best model for production\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" Data loaded from: /content/research\")\n",
    "print(\" Results saved to: /content/drive/MyDrive/research\")\n",
    "print(\"=\" * 60)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix: Quick Commands\n",
    "\n",
    "```bash\n",
    "# Train single model\n",
    "!python scripts/train_model.py --model xgboost --horizon 20\n",
    "\n",
    "# Train neural model\n",
    "!python scripts/train_model.py --model lstm --horizon 20 --seq-len 60\n",
    "\n",
    "# Run cross-validation\n",
    "!python scripts/run_cv.py --models xgboost,lightgbm --horizons 20 --n-splits 5\n",
    "\n",
    "# Train ensemble\n",
    "!python scripts/train_model.py --model voting --horizon 20\n",
    "\n",
    "# List all models\n",
    "!python scripts/train_model.py --list-models\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}