# XGBoost Configuration
# Gradient boosting with tree-based weak learners
# GPU: Supports CUDA acceleration with tree_method='hist' and device='cuda'

# Model identification
model:
  name: xgboost
  family: boosting
  description: Gradient boosted decision trees with GPU support

# Default hyperparameters
defaults:
  # Tree parameters
  n_estimators: 500
  max_depth: 6
  min_child_weight: 10
  subsample: 0.8
  colsample_bytree: 0.8

  # Learning
  learning_rate: 0.05
  gamma: 0.1

  # Regularization
  reg_alpha: 0.1       # L1 regularization
  reg_lambda: 1.0      # L2 regularization

  # Training
  early_stopping_rounds: 50
  eval_metric: mlogloss
  tree_method: hist    # Fast histogram-based algorithm (required for GPU)

  # Class imbalance
  scale_pos_weight: null  # Auto-computed from class distribution

# Training settings
training:
  feature_set: boosting_optimal
  random_seed: 42
  n_jobs: -1           # All CPU cores when not using GPU
  verbosity: 1         # 0=silent, 1=warning, 2=info

# Device settings
device:
  default: auto        # auto, cuda, or cpu
  use_gpu: true        # Enable GPU acceleration if available
  mixed_precision: false  # Not applicable to tree methods
